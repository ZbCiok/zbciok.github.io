"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[2346],{2470:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>h});const s=JSON.parse('{"id":"streams/apache-spark/index","title":"Apache Spark","description":"https://spark.apache.org/","source":"@site/docs/streams/apache-spark/index.mdx","sourceDirName":"streams/apache-spark","slug":"/apache-spark","permalink":"/docs/apache-spark","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"slug":"/apache-spark"},"sidebar":"tutorialSidebar","previous":{"title":"References","permalink":"/docs/streams/apache-flink/references"},"next":{"title":"Spark Architecture","permalink":"/docs/streams/apache-spark/spark-architecture"}}');var n=t(4848),a=t(8453),i=t(7170),l=t(3304);const o={slug:"/apache-spark"},c="Apache Spark",d={},h=[{value:"Key features",id:"key-features",level:2},{value:"Flink vs. Spark",id:"flink-vs-spark",level:2},{value:"Summary of differences: Flink vs. Spark",id:"summary-of-differences-flink-vs-spark",level:2},{value:"Install Spark",id:"install-spark",level:2},{value:"Ubuntu",id:"ubuntu",level:3},{value:"Start Standalone Spark Master Server",id:"start-standalone-spark-master-server",level:4},{value:"Start Spark Worker Server (Start a Worker Process)",id:"start-spark-worker-server-start-a-worker-process",level:5},{value:"Test Spark Shell",id:"test-spark-shell",level:2},{value:"Basic Commands to Start and Stop Master Server and Workers",id:"basic-commands-to-start-and-stop-master-server-and-workers",level:2},{value:"Quick Start",id:"quick-start",level:2}];function p(e){const r={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.header,{children:(0,n.jsx)(r.h1,{id:"apache-spark",children:"Apache Spark"})}),"\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:(0,n.jsx)(r.a,{href:"https://spark.apache.org/",children:"https://spark.apache.org/"})})})," ",(0,n.jsx)("br",{}),"\n",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:(0,n.jsx)(r.a,{href:"https://sparkbyexamples.com/",children:"https://sparkbyexamples.com/"})})})," ",(0,n.jsx)("br",{})]}),"\n",(0,n.jsx)(r.p,{children:"Unified engine for large-scale data analytics."}),"\n",(0,n.jsx)(r.p,{children:"Apache Spark\u2122 is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters."}),"\n",(0,n.jsx)(r.h2,{id:"key-features",children:"Key features"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:"Batch/streaming data\nUnify the processing of your data in batches and real-time streaming, using your preferred language: Python, SQL, Scala, Java or R."}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:"SQL analytics\nExecute fast, distributed ANSI SQL queries for dashboarding and ad-hoc reporting. Runs faster than most data warehouses."}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:"Data science at scale\nPerform Exploratory Data Analysis (EDA) on petabyte-scale data without having to resort to downsampling"}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:"Machine learning\nTrain machine learning algorithms on a laptop and use the same code to scale to fault-tolerant clusters of thousands of machines."}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(r.h2,{id:"flink-vs-spark",children:"Flink vs. Spark"}),"\n",(0,n.jsx)(r.p,{children:"Stream processing is a continuous method of ingesting, analyzing, and processing data as it is generated. The input data is unbounded and has no predetermined beginning or end. It is a series of events that arrive at the stream processing system (e.g., credit card transactions, clicks on a website, or sensor readings from Internet of Things [IoT] devices)."}),"\n",(0,n.jsx)(r.p,{children:"Two prominent technologies, Apache Spark\u2122, and Apache Flink\xae, are leading frameworks in stream processing. Where Spark initially gained popularity for batch processing, it has since evolved to incorporate structured streaming for real-time data analysis. In contrast, Flink was built from the ground up for real-time processing and can do batch processing too. Despite their distinct origins, both excel as low-latency and scalable technologies."}),"\n",(0,n.jsx)(r.p,{children:"This article explores the two frameworks, their features, and why they are often compared in the context of real-time data analysis."}),"\n",(0,n.jsx)(r.h2,{id:"summary-of-differences-flink-vs-spark",children:"Summary of differences: Flink vs. Spark"}),"\n",(0,n.jsxs)(r.table,{children:[(0,n.jsx)(r.thead,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.th,{}),(0,n.jsx)(r.th,{children:"Spark"}),(0,n.jsx)(r.th,{children:"Flink"})]})}),(0,n.jsxs)(r.tbody,{children:[(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"Data ingestion tool"}),(0,n.jsx)(r.td,{children:"Spark Streaming Sources"}),(0,n.jsx)(r.td,{children:"Flink Data Stream API"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"Data processing"}),(0,n.jsx)(r.td,{children:"Batch/Stream (Micro Batch)"}),(0,n.jsx)(r.td,{children:"Batch/Stream (Real-time)"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"Windowing"}),(0,n.jsx)(r.td,{children:"Tumbling/Sliding"}),(0,n.jsx)(r.td,{children:"Tumbling/Sliding/Session/Global"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"Joins"}),(0,n.jsx)(r.td,{children:"Stream-stream/Stream-dataset"}),(0,n.jsx)(r.td,{children:"Window/Interval"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"State backend"}),(0,n.jsx)(r.td,{children:"HDFS"}),(0,n.jsx)(r.td,{children:"In-memory/RocksDB"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"Fault tolerance"}),(0,n.jsx)(r.td,{children:"Yes (WAL)"}),(0,n.jsx)(r.td,{children:"Yes (Chandy-Lamport)"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"User-defined functions"}),(0,n.jsx)(r.td,{children:"Yes"}),(0,n.jsx)(r.td,{children:"Yes"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"Languages"}),(0,n.jsx)(r.td,{children:"Scala, Java, Python, R, and SQL"}),(0,n.jsx)(r.td,{children:"Java, Python, SQL, and Scala (deprecated)"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"API/Libraries"}),(0,n.jsx)(r.td,{children:"Spark Streaming, Spark SQL,"}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{}),(0,n.jsx)(r.td,{children:"MLlib for machine learning,"}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{}),(0,n.jsx)(r.td,{children:"GraphX for graph processing,"}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{}),(0,n.jsx)(r.td,{children:"PySpark"}),(0,n.jsx)(r.td,{children:"DataStream API, Table API, Flink SQL,"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{}),(0,n.jsx)(r.td,{}),(0,n.jsx)(r.td,{children:"Flink ML, Gelly, PyFlink"})]})]})]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"install-spark",children:"Install Spark"}),"\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.a,{href:"https://phoenixnap.com/kb/install-spark-on-ubuntu",children:(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"How to Install Spark on Ubuntu"})})})," ",(0,n.jsx)("br",{}),"\n",(0,n.jsx)(r.a,{href:"https://spark.apache.org/docs/latest/quick-start.html",children:(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"Interactive Analysis with the Spark Shell"})})}),"  ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"(with install)"})}),(0,n.jsx)("br",{})]}),"\n",(0,n.jsx)(r.h3,{id:"ubuntu",children:"Ubuntu"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{children:"export SPARK_HOME=/opt/spark\nexport PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\nexport PYSPARK_PYTHON=/usr/bin/python3\n"})}),"\n",(0,n.jsx)(r.h4,{id:"start-standalone-spark-master-server",children:"Start Standalone Spark Master Server"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{children:"start-master.sh\n"})}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{children:"http://127.0.0.1:8080/\n"})}),"\n",(0,n.jsx)(r.h5,{id:"start-spark-worker-server-start-a-worker-process",children:"Start Spark Worker Server (Start a Worker Process)"}),"\n",(0,n.jsx)(r.p,{children:"Use the following command format to start a worker server in a single-server setup:"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{children:"start-worker.sh spark://[master_server]:[port]\n"})}),"\n",(0,n.jsx)(r.h2,{id:"test-spark-shell",children:"Test Spark Shell"}),"\n",(0,n.jsxs)(r.p,{children:["To load the ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"Scala shell"})}),", enter:"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{children:"spark-shell\n"})}),"\n",(0,n.jsxs)(r.p,{children:["Type ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:":q"})})," and press ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"Enter"})})," to exit Scala."]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsxs)(r.p,{children:["Enter the following command to start the ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"PySpark shell"})})," (Python):"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{children:"pyspark\n"})}),"\n",(0,n.jsxs)(r.p,{children:["To exit the PySpark shell, type ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"quit()"})})," and press ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"Enter"})}),"."]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"basic-commands-to-start-and-stop-master-server-and-workers",children:"Basic Commands to Start and Stop Master Server and Workers"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{children:"Command           Description\nstart-master.sh   Start the driver (master) server instance on the current machine.\nstop-master.sh    Stop the driver (master) server instance on the current machine.\nstart-worker.sh   spark://master_server:port\tStart a worker process and connect it to the master server (use the master's IP or hostname).\nstop-worker.sh    Stop a running worker process.\nstart-all.sh      Start both the driver (master) and worker instances.\nstop-all.sh       Stop all the driver (master) and worker instances.\n\nThe start-all.sh and stop-all.sh commands work for single-node setups, but in multi-node clusters, you must configure passwordless SSH login on each node. This allows the master server to control the worker nodes remotely.\n"})}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.a,{href:"https://spark.apache.org/docs/latest/quick-start.html",children:(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"Quick Start"})})})," ",(0,n.jsx)("br",{})]}),"\n",(0,n.jsxs)(r.admonition,{title:"citation",type:"info",children:[(0,n.jsx)(r.p,{children:"This tutorial provides a quick introduction to using Spark. We will first introduce the API through Spark\u2019s interactive shell (in Python or Scala), then show how to write applications in Java, Scala, and Python."}),(0,n.jsxs)(r.p,{children:["To follow along with this guide, first, download a packaged release of Spark from the ",(0,n.jsx)(r.a,{href:"https://spark.apache.org/downloads.html",children:(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"Spark website"})})}),". Since we won\u2019t be using HDFS, you can download a package for any version of Hadoop."]}),(0,n.jsxs)(r.p,{children:["Note that, before Spark 2.0, the main programming interface of Spark was the Resilient Distributed Dataset (RDD). After Spark 2.0, RDDs are replaced by Dataset, which is strongly-typed like an RDD, but with richer optimizations under the hood. The RDD interface is still supported, and you can get a more detailed reference at the ",(0,n.jsx)(r.a,{href:"https://spark.apache.org/docs/latest/rdd-programming-guide.html",children:(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"RDD programming guide"})})}),". However, we highly recommend you to switch to use Dataset, which has better performance than RDD. See the ",(0,n.jsx)(r.a,{href:"https://spark.apache.org/docs/latest/sql-programming-guide.html",children:(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"SQL programming guide"})})})," to get more information about Dataset."]})]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)("br",{}),"\n",(0,n.jsx)("br",{}),"\n","\n",(0,n.jsx)(i.A,{items:(0,l.$S)().items})]})}function u(e={}){const{wrapper:r}={...(0,a.R)(),...e.components};return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(p,{...e})}):p(e)}},4365:(e,r,t)=>{t.d(r,{W:()=>c});var s=t(6540),n=t(502);const a=["zero","one","two","few","many","other"];function i(e){return a.filter((r=>e.includes(r)))}const l={locale:"en",pluralForms:i(["one","other"]),select:e=>1===e?"one":"other"};function o(){const{i18n:{currentLocale:e}}=(0,n.A)();return(0,s.useMemo)((()=>{try{return function(e){const r=new Intl.PluralRules(e);return{locale:e,pluralForms:i(r.resolvedOptions().pluralCategories),select:e=>r.select(e)}}(e)}catch(r){return console.error(`Failed to use Intl.PluralRules for locale "${e}".\nDocusaurus will fallback to the default (English) implementation.\nError: ${r.message}\n`),l}}),[e])}function c(){const e=o();return{selectMessage:(r,t)=>function(e,r,t){const s=e.split("|");if(1===s.length)return s[0];s.length>t.pluralForms.length&&console.error(`For locale=${t.locale}, a maximum of ${t.pluralForms.length} plural forms are expected (${t.pluralForms.join(",")}), but the message contains ${s.length}: ${e}`);const n=t.select(r),a=t.pluralForms.indexOf(n);return s[Math.min(a,s.length-1)]}(t,r,e)}}},7170:(e,r,t)=>{t.d(r,{A:()=>k});t(6540);var s=t(4164),n=t(7936),a=t(7634),i=t(4365),l=t(5242),o=t(9979),c=t(4861);const d={cardContainer:"cardContainer_fWXF",cardTitle:"cardTitle_rnsV",cardDescription:"cardDescription_PWke"};var h=t(4848);function p(e){let{href:r,children:t}=e;return(0,h.jsx)(a.A,{href:r,className:(0,s.A)("card padding--lg",d.cardContainer),children:t})}function u(e){let{href:r,icon:t,title:n,description:a}=e;return(0,h.jsxs)(p,{href:r,children:[(0,h.jsxs)(c.A,{as:"h2",className:(0,s.A)("text--truncate",d.cardTitle),title:n,children:[t," ",n]}),a&&(0,h.jsx)("p",{className:(0,s.A)("text--truncate",d.cardDescription),title:a,children:a})]})}function m(e){let{item:r}=e;const t=(0,n.Nr)(r),s=function(){const{selectMessage:e}=(0,i.W)();return r=>e(r,(0,o.T)({message:"1 item|{count} items",id:"theme.docs.DocCard.categoryDescription.plurals",description:"The default description for a category card in the generated index about how many items this category includes"},{count:r}))}();return t?(0,h.jsx)(u,{href:t,icon:"\ud83d\uddc3\ufe0f",title:r.label,description:r.description??s(r.items.length)}):null}function x(e){let{item:r}=e;const t=(0,l.A)(r.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",s=(0,n.cC)(r.docId??void 0);return(0,h.jsx)(u,{href:r.href,icon:t,title:r.label,description:r.description??s?.description})}function j(e){let{item:r}=e;switch(r.type){case"link":return(0,h.jsx)(x,{item:r});case"category":return(0,h.jsx)(m,{item:r});default:throw new Error(`unknown item type ${JSON.stringify(r)}`)}}function g(e){let{className:r}=e;const t=(0,n.$S)();return(0,h.jsx)(k,{items:t.items,className:r})}function k(e){const{items:r,className:t}=e;if(!r)return(0,h.jsx)(g,{...e});const a=(0,n.d1)(r);return(0,h.jsx)("section",{className:(0,s.A)("row",t),children:a.map(((e,r)=>(0,h.jsx)("article",{className:"col col--6 margin-bottom--lg",children:(0,h.jsx)(j,{item:e})},r)))})}},8453:(e,r,t)=>{t.d(r,{R:()=>i,x:()=>l});var s=t(6540);const n={},a=s.createContext(n);function i(e){const r=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:i(e.components),s.createElement(a.Provider,{value:r},e.children)}}}]);