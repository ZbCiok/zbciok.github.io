"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[334],{8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>i});var t=a(6540);const r={},s=t.createContext(r);function o(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:n},e.children)}},9071:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>p,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"apache-spark/examples/python-spark-DataFrame","title":"Python Spark DataFrame","description":"https://spark.apache.org/examples.html","source":"@site/docs/apache-spark/examples/python-spark-DataFrame.mdx","sourceDirName":"apache-spark/examples","slug":"/apache-spark/examples/python-spark-DataFrame","permalink":"/docs/apache-spark/examples/python-spark-DataFrame","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":120,"frontMatter":{"sidebar_position":120},"sidebar":"tutorialSidebar","previous":{"title":"Python Spark Quickstart","permalink":"/docs/apache-spark/examples/python-spark-quickstart"},"next":{"title":"Python Spark SQL 01","permalink":"/docs/apache-spark/examples/python-spark-sql-01"}}');var r=a(4848),s=a(8453);const o={sidebar_position:120},i="Python Spark DataFrame",p={},h=[{value:"Description",id:"description",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Change",id:"change",level:3},{value:"python-spark-DataFrame.py",id:"python-spark-dataframepy",level:2},{value:"Run",id:"run",level:2},{value:"Output",id:"output",level:4}];function l(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"python-spark-dataframe",children:"Python Spark DataFrame"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://spark.apache.org/examples.html",children:"https://spark.apache.org/examples.html"})})})," ",(0,r.jsx)("br",{})]}),"\n",(0,r.jsx)(n.h2,{id:"description",children:"Description"}),"\n",(0,r.jsx)("img",{src:"/img/streams/spark/06-dataframe-picture.png",width:"300 px",alt:"06-dataframe-picture.png"}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.p,{children:"This section shows you how to create a Spark DataFrame and run simple operations. The examples are on a small DataFrame, so you can easily see the functionality."}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Python"}),"\n",(0,r.jsx)(n.li,{children:"Spark"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"change",children:"Change"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"spark/conf/log4j2.properties"})}),":",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"rootLogger.level = info --\x3e rootLogger.level = error"})})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:["Go to ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"spark/my-examples"})})," and create:"]}),"\n",(0,r.jsx)(n.h2,{id:"python-spark-dataframepy",children:"python-spark-DataFrame.py"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName("demo").getOrCreate()\n\nprint("Create a Spark DataFrame:")\ndf = spark.createDataFrame(\n    [\n        ("sue", 32),\n        ("li", 3),\n        ("bob", 75),\n        ("heo", 13),\n    ],\n    ["first_name", "age"],\n)\nprint("...\\n\\n")\n\nprint("Use the show() method to view the contents of the DataFrame:")\ndf.show()\n\nprint("Now, let\u2019s perform some data processing operations on the DataFrame.")\nprint("\\n")\nprint("ADD a COLUMN TO a SPARK DataFrame:")\nfrom pyspark.sql.functions import col, when\n\ndf1 = df.withColumn(\n    "life_stage",\n    when(col("age") < 13, "child")\n    .when(col("age").between(13, 19), "teenager")\n    .otherwise("adult"),\n)\nprint("...\\n\\n")\n\nprint("Let\u2019s view the contents of df1.")\ndf1.show()\n\nprint("Notice how the original DataFrame is unchanged:")\ndf.show()\n\nprint("FILTER a SPARK DataFrame")\nprint("Now, filter the DataFrame so it only includes teenagers and adults.")\ndf1.where(col("life_stage").isin(["teenager", "adult"])).show()\n\nprint("GROUP BY AGGREGATION ON SPARK DataFrame")\nprint("Now, let\u2019s compute the average age for everyone in the dataset:")\nfrom pyspark.sql.functions import avg\ndf1.select(avg("age")).show()\n\nprint("You can also compute the average age for each life_stage:")\ndf1.groupBy("life_stage").avg().show()\n\nprint("\\nSpark lets you run queries on DataFrames with SQL if you don\u2019t want to use the programmatic APIs.")\nprint("QUERY THE DataFrame WITH SQL")\nprint("Here\u2019s how you can compute the average age for everyone with SQL:")\nspark.sql("select avg(age) from {df1}", df1=df1).show()\n\nprint("And here\u2019s how to compute the average age by life_stage with SQL:")\nspark.sql("select life_stage, avg(age) from {df1} group by life_stage", df1=df1).show()\n'})}),"\n",(0,r.jsx)(n.h2,{id:"run",children:"Run"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"./bin/spark-submit --master local[4] ./my-examples/python-spark-DataFrame.py\n"})}),"\n",(0,r.jsx)(n.h4,{id:"output",children:"Output"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Create a Spark DataFrame:\n...\n\n\nUse the show() method to view the contents of the DataFrame:\n+----------+---+\n|first_name|age|\n+----------+---+\n|       sue| 32|\n|        li|  3|\n|       bob| 75|\n|       heo| 13|\n+----------+---+\n\nNow, let\u2019s perform some data processing operations on the DataFrame.\n\n\nADD a COLUMN TO a SPARK DataFrame:\n...\n\n\nLet\u2019s view the contents of df1.\n+----------+---+----------+\n|first_name|age|life_stage|\n+----------+---+----------+\n|       sue| 32|     adult|\n|        li|  3|     child|\n|       bob| 75|     adult|\n|       heo| 13|  teenager|\n+----------+---+----------+\n\nNotice how the original DataFrame is unchanged:\n+----------+---+\n|first_name|age|\n+----------+---+\n|       sue| 32|\n\n...\n...\n"})})]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);