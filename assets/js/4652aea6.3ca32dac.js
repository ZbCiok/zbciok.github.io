"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[9443],{5:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>i,contentTitle:()=>l,default:()=>c,frontMatter:()=>p,metadata:()=>n,toc:()=>o});const n=JSON.parse('{"id":"streams/apache-spark/examples/python-spark-sql-02","title":"Python Spark SQL 02","description":"Spark SQL","source":"@site/docs/streams/apache-spark/examples/python-spark-sql-02.mdx","sourceDirName":"streams/apache-spark/examples","slug":"/streams/apache-spark/examples/python-spark-sql-02","permalink":"/docs/streams/apache-spark/examples/python-spark-sql-02","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":160,"frontMatter":{"sidebar_position":160},"sidebar":"tutorialSidebar","previous":{"title":"Python Spark SQL 01","permalink":"/docs/streams/apache-spark/examples/python-spark-sql-01"},"next":{"title":"References","permalink":"/docs/streams/apache-spark/references"}}');var s=a(4848),r=a(8453);const p={sidebar_position:160},l="Python Spark SQL 02",i={},o=[{value:"Description",id:"description",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"python-spark-sql-02.py",id:"python-spark-sql-02py",level:2},{value:"Run",id:"run",level:2},{value:"Output",id:"output",level:4}];function d(e){const t={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"python-spark-sql-02",children:"Python Spark SQL 02"})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html",children:(0,s.jsx)(t.em,{children:(0,s.jsx)(t.strong,{children:"Spark SQL"})})})," ",(0,s.jsx)("br",{})]}),"\n",(0,s.jsx)(t.h2,{id:"description",children:"Description"}),"\n",(0,s.jsx)("img",{src:"/img/streams/spark/07-sql-dataframe-picture.png",width:"300 px",alt:"07-sql-dataframe-picture.png"}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(t.p,{children:"This Example - How to get list of databases and tables from spark catalog."}),"\n",(0,s.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Python"}),"\n",(0,s.jsx)(t.li,{children:"Spark"}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["Go to ",(0,s.jsx)(t.em,{children:(0,s.jsx)(t.strong,{children:"spark/my-examples"})})," and create:"]}),"\n",(0,s.jsx)(t.h2,{id:"python-spark-sql-02py",children:"python-spark-sql-02.py"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:'\nprint ("import SparkContext")\nfrom datetime import date\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructField, StringType, StructType, IntegerType, DateType, DecimalType\nfrom decimal import Decimal\n\nprint("Connect to spark cluster on local")\nsc = SparkSession.builder.config(\'spark.driver.host\',\'localhost\').appName(\'My_Pyspark_Test\').getOrCreate()\n\nprint("define department dept_df schema")\ndept_schema = StructType([\n    StructField(\'deptid\', IntegerType(), False), StructField(\'deptname\', StringType(), False)\n])\n\nprint("define department dept_df data")\ndept_data = [(10, \'Human Resources\'), (20, \'Infrastructure\'), (30, \'Administration\'), (40, \'Governance\')]\n\nprint("define employee emp_df schema")\nemp_schema = StructType([\n    StructField(\'empid\', IntegerType(), False), StructField(\'ename\', StringType(), False), StructField(\'deptid\', IntegerType(), False), StructField(\'doj\', DateType(), False),\n    StructField(\'salary\', DecimalType(), False)\n])\n\nprint("define employee emp_df data")\nemp_data = [\n    (1, \'Patrick\', 10, date(2015, 1, 1), Decimal(1000.00)), (2, \'Lisbon\', 10, date(2016, 1, 1), Decimal(1500.00)), (3, \'Cho\', 20, date(2017, 1, 1), Decimal(800.00)),\n    (4, \'Rigsby\', 20, date(2018, 1, 1), Decimal(200.00)), (5, \'VanPelt\', 30, date(2019, 1, 2), Decimal(8000.00)), (6, \'Charlotte\', 30, date(2020, 1, 1), Decimal(5000.00))\n]\n\nprint("\\ncreate department dataframe")\ndept_df = sc.createDataFrame(data = dept_data, schema = dept_schema)\ndept_df.show()\n\nprint("\\ncreate employee dataframe")\nemp_df = sc.createDataFrame(data = emp_data, schema = emp_schema)\nemp_df.show()\n\nprint("DROP TABLE IF EXISTS department_tbl")\nsc.sql("DROP TABLE IF EXISTS department_tbl")\n\nprint("\\nwrite to hive table department_tbl")\ndept_df.write.saveAsTable("department_tbl")\n\nprint("write to hive table employee_tbl")\nemp_df.write.saveAsTable("employee_tbl")\n\nprint("\\nshow all the catalog information")\ncatalog = sc.catalog\nprint(catalog.listDatabases())\nprint(catalog.listTables())\n\nprint("show metadata of any table")\nmetadata = catalog.getTable("employee_tbl")\nprint(metadata.name)\nprint(metadata.database)\nfor column in catalog.listColumns("employee_tbl"):\n    print("Column name is " + column.name + " and column type is " + column.dataType)\n\nprint("drop the tables")\nsc.sql("DROP TABLE IF EXISTS department_tbl")\nsc.sql("DROP TABLE IF EXISTS employee_tbl")\n\n\n\nprint("\\nstop the spark session")\nsc.stop()\n'})}),"\n",(0,s.jsx)(t.h2,{id:"run",children:"Run"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"./bin/spark-submit --master local[4] ./my-examples/python-spark-sql-02.py\n"})}),"\n",(0,s.jsx)(t.h4,{id:"output",children:"Output"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"import SparkContext\nConnect to spark cluster on local\ndefine department dept_df schema\ndefine department dept_df data\ndefine employee emp_df schema\ndefine employee emp_df data\n\ncreate department dataframe\n+------+---------------+\n|deptid|       deptname|\n+------+---------------+\n|    10|Human Resources|\n|    20| Infrastructure|\n|    30| Administration|\n|    40|     Governance|\n+------+---------------+\n\n\ncreate employee dataframe\n+-----+---------+------+----------+------+\n|empid|    ename|deptid|       doj|salary|\n+-----+---------+------+----------+------+\n|    1|  Patrick|    10|2015-01-01|  1000|\n|    2|   Lisbon|    10|2016-01-01|  1500|\n|    3|      Cho|    20|2017-01-01|   800|\n|    4|   Rigsby|    20|2018-01-01|   200|\n|    5|  VanPelt|    30|2019-01-02|  8000|\n|    6|Charlotte|    30|2020-01-01|  5000|\n+-----+---------+------+----------+------+\n\nDROP TABLE IF EXISTS department_tbl\n\nwrite to hive table department_tbl\nwrite to hive table employee_tbl\n\nshow all the catalog information\n[Database(name='default', catalog='spark_catalog', description='default database', locationUri='file:/opt/spark/spark-warehouse')]\n[Table(name='department_tbl', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False), Table(name='employee_tbl', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False)]\nshow metadata of any table\nemployee_tbl\ndefault\nColumn name is empid and column type is int\nColumn name is ename and column type is string\nColumn name is deptid and column type is int\nColumn name is doj and column type is date\nColumn name is salary and column type is decimal(10,0)\ndrop the tables\n\nstop the spark session\n"})}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:["On the base:",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(t.a,{href:"https://medium.com/@softwareprocesspains2023/pyspark-how-to-get-list-of-databases-and-tables-from-spark-catalog-108f167fbba9",children:(0,s.jsx)(t.em,{children:(0,s.jsx)(t.strong,{children:"Pyspark \u2014 How to get list of databases and tables from spark catalog"})})})," ",(0,s.jsx)("br",{})]})]})}function c(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,t,a)=>{a.d(t,{R:()=>p,x:()=>l});var n=a(6540);const s={},r=n.createContext(s);function p(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:p(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);