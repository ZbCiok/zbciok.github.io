"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[671],{8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var s=t(6540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}},8827:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"streams/ksqlDB/confluent-platform","title":"Confluent Platform","description":"Running locally with Confluent Platform and its main components using Docker containers.","source":"@site/docs/streams/ksqlDB/confluent-platform.mdx","sourceDirName":"streams/ksqlDB","slug":"/streams/ksqlDB/confluent-platform","permalink":"/docs/streams/ksqlDB/confluent-platform","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":100,"frontMatter":{"sidebar_position":100},"sidebar":"tutorialSidebar","previous":{"title":"ksqlDB","permalink":"/docs/ksqlDB"},"next":{"title":"Materialized Views","permalink":"/docs/streams/ksqlDB/materialized-views"}}');var r=t(4848),i=t(8453);const o={sidebar_position:100},a="Confluent Platform",l={},c=[{value:"I. Download and start Confluent Platform",id:"i-download-and-start-confluent-platform",level:2},{value:"Start the Confluent Platform",id:"start-the-confluent-platform",level:3},{value:"Result:",id:"result",level:4},{value:"Verify that the services are up and running:",id:"verify-that-the-services-are-up-and-running",level:3},{value:"Your output should resemble:",id:"your-output-should-resemble",level:4},{value:"II. Uninstall and clean up",id:"ii-uninstall-and-clean-up",level:2},{value:"Stop Docker",id:"stop-docker",level:3},{value:"Prune the Docker",id:"prune-the-docker",level:3},{value:"III. Create Kafka topics for storing your data",id:"iii-create-kafka-topics-for-storing-your-data",level:2},{value:"Create the pageviews topic",id:"create-the-pageviews-topic",level:3},{value:"Create the users topic with defaults",id:"create-the-users-topic-with-defaults",level:3},{value:"IV. Generate mock data",id:"iv-generate-mock-data",level:2},{value:"Run a second instance of the Datagen Source connector to produce mock data to the <em><strong>users</strong></em> topic.",id:"run-a-second-instance-of-the-datagen-source-connector-to-produce-mock-data-to-the-users-topic",level:4},{value:"Inspect the schema of a topic",id:"inspect-the-schema-of-a-topic",level:4},{value:"V. Create a stream and table by using SQL statements",id:"v-create-a-stream-and-table-by-using-sql-statements",level:2},{value:"CREATE STREAM",id:"create-stream",level:3},{value:"Run query",id:"run-query",level:3},{value:"Use a SELECT query to confirm that data is moving through your stream.",id:"use-a-select-query-to-confirm-that-data-is-moving-through-your-stream",level:3},{value:"Stopping the SELECT query doesn\u2019t stop data movement through the stream.",id:"stopping-the-select-query-doesnt-stop-data-movement-through-the-stream",level:4},{value:"CREATE TABLE",id:"create-table",level:3},{value:"Output",id:"output",level:4},{value:"Inspect the schemas of your stream and table",id:"inspect-the-schemas-of-your-stream-and-table",level:4},{value:"VI. Create queries to process data",id:"vi-create-queries-to-process-data",level:2},{value:"Query for <em><strong>pageviews</strong></em>",id:"query-for-pageviews",level:3},{value:"Join your stream and table",id:"join-your-stream-and-table",level:3},{value:"Filter a stream",id:"filter-a-stream",level:3},{value:"Your output should resemble:",id:"your-output-should-resemble-1",level:4},{value:"Create a windowed view",id:"create-a-windowed-view",level:3},{value:"Your output should resemble:",id:"your-output-should-resemble-2",level:4},{value:"Your output should resemble:",id:"your-output-should-resemble-3",level:4},{value:"The NUMVIEWS column shows the count of views in a 30-second window.",id:"the-numviews-column-shows-the-count-of-views-in-a-30-second-window",level:4},{value:"Snapshot a table by using a pull query",id:"snapshot-a-table-by-using-a-pull-query",level:3},{value:"Inspect your streams and tables",id:"inspect-your-streams-and-tables",level:3},{value:"<em><strong>All available streams and tables:</strong></em>",id:"all-available-streams-and-tables",level:4},{value:"Visualize your app\u2019s stream topology",id:"visualize-your-apps-stream-topology",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"confluent-platform",children:"Confluent Platform"})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/architecture-02.png",alt:"architecture-02.png"}),"\n",(0,r.jsx)(n.p,{children:"Running locally with Confluent Platform and its main components using Docker containers."}),"\n",(0,r.jsx)(n.p,{children:"In this quick start, you create Apache Kafka\xae topics, use Kafka Connect to generate mock data to those topics, and create ksqlDB streaming queries on those topics. You then go to Confluent Control Center to monitor and analyze the event streaming queries. When you finish, you\u2019ll have a real-time app that consumes and processes data streams by using familiar SQL statements."}),"\n",(0,r.jsx)(n.h2,{id:"i-download-and-start-confluent-platform",children:"I. Download and start Confluent Platform"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/get-started/platform-quickstart.html#step-1-download-and-start-cp",children:(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Quick Start for Confluent Platform"})})})}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"wget https://raw.githubusercontent.com/confluentinc/cp-all-in-one/7.8.0-post/cp-all-in-one-kraft/docker-compose.yml\n"})}),"\n",(0,r.jsxs)(n.p,{children:["As a result, you get:\n",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"docker-compose.yml:"})})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'---\nservices:\n\n  broker:\n    image: confluentinc/cp-kafka:7.8.0\n    hostname: broker\n    container_name: broker\n    ports:\n      - "9092:9092"\n      - "9101:9101"\n    environment:\n      KAFKA_NODE_ID: 1\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: \'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\'\n      KAFKA_ADVERTISED_LISTENERS: \'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092\'\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0\n      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\n      KAFKA_JMX_PORT: 9101\n      KAFKA_JMX_HOSTNAME: localhost\n      KAFKA_PROCESS_ROLES: \'broker,controller\'\n      KAFKA_CONTROLLER_QUORUM_VOTERS: \'1@broker:29093\'\n      KAFKA_LISTENERS: \'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092\'\n      KAFKA_INTER_BROKER_LISTENER_NAME: \'PLAINTEXT\'\n      KAFKA_CONTROLLER_LISTENER_NAMES: \'CONTROLLER\'\n      KAFKA_LOG_DIRS: \'/tmp/kraft-combined-logs\'\n      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"\n      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh\n      CLUSTER_ID: \'MkU3OEVBNTcwNTJENDM2Qk\'\n\n  schema-registry:\n    image: confluentinc/cp-schema-registry:7.8.0\n    hostname: schema-registry\n    container_name: schema-registry\n    depends_on:\n      - broker\n    ports:\n      - "8081:8081"\n    environment:\n      SCHEMA_REGISTRY_HOST_NAME: schema-registry\n      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: \'broker:29092\'\n      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081\n\n  connect:\n    image: cnfldemos/cp-server-connect-datagen:0.6.4-7.6.0\n    hostname: connect\n    container_name: connect\n    depends_on:\n      - broker\n      - schema-registry\n    ports:\n      - "8083:8083"\n    environment:\n      CONNECT_BOOTSTRAP_SERVERS: \'broker:29092\'\n      CONNECT_REST_ADVERTISED_HOST_NAME: connect\n      CONNECT_GROUP_ID: compose-connect-group\n      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs\n      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1\n      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000\n      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets\n      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1\n      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status\n      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1\n      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter\n      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter\n      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081\n      # CLASSPATH required due to CC-2422\n      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.8.0.jar\n      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"\n      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"\n      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"\n\n  control-center:\n    image: confluentinc/cp-enterprise-control-center:7.8.0\n    hostname: control-center\n    container_name: control-center\n    depends_on:\n      - broker\n      - schema-registry\n      - connect\n      - ksqldb-server\n    ports:\n      - "9021:9021"\n    environment:\n      CONTROL_CENTER_BOOTSTRAP_SERVERS: \'broker:29092\'\n      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: \'connect:8083\'\n      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: \'/connectors\'\n      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"\n      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"\n      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"\n      CONTROL_CENTER_REPLICATION_FACTOR: 1\n      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1\n      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1\n      CONFLUENT_METRICS_TOPIC_REPLICATION: 1\n      PORT: 9021\n\n  ksqldb-server:\n    image: confluentinc/cp-ksqldb-server:7.8.0\n    hostname: ksqldb-server\n    container_name: ksqldb-server\n    depends_on:\n      - broker\n      - connect\n    ports:\n      - "8088:8088"\n    environment:\n      KSQL_CONFIG_DIR: "/etc/ksql"\n      KSQL_BOOTSTRAP_SERVERS: "broker:29092"\n      KSQL_HOST_NAME: ksqldb-server\n      KSQL_LISTENERS: "http://0.0.0.0:8088"\n      KSQL_CACHE_MAX_BYTES_BUFFERING: 0\n      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"\n      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"\n      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"\n      KSQL_KSQL_CONNECT_URL: "http://connect:8083"\n      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1\n      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: \'true\'\n      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: \'true\'\n\n  ksqldb-cli:\n    image: confluentinc/cp-ksqldb-cli:7.8.0\n    container_name: ksqldb-cli\n    depends_on:\n      - broker\n      - connect\n      - ksqldb-server\n    entrypoint: /bin/sh\n    tty: true\n\n  ksql-datagen:\n    image: confluentinc/ksqldb-examples:7.8.0\n    hostname: ksql-datagen\n    container_name: ksql-datagen\n    depends_on:\n      - ksqldb-server\n      - broker\n      - schema-registry\n      - connect\n    command: "bash -c \'echo Waiting for Kafka to be ready... && \\\n                       cub kafka-ready -b broker:29092 1 40 && \\\n                       echo Waiting for Confluent Schema Registry to be ready... && \\\n                       cub sr-ready schema-registry 8081 40 && \\\n                       echo Waiting a few seconds for topic creation to finish... && \\\n                       sleep 11 && \\\n                       tail -f /dev/null\'"\n    environment:\n      KSQL_CONFIG_DIR: "/etc/ksql"\n      STREAMS_BOOTSTRAP_SERVERS: broker:29092\n      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry\n      STREAMS_SCHEMA_REGISTRY_PORT: 8081\n\n  rest-proxy:\n    image: confluentinc/cp-kafka-rest:7.8.0\n    depends_on:\n      - broker\n      - schema-registry\n    ports:\n      - 8082:8082\n    hostname: rest-proxy\n    container_name: rest-proxy\n    environment:\n      KAFKA_REST_HOST_NAME: rest-proxy\n      KAFKA_REST_BOOTSTRAP_SERVERS: \'broker:29092\'\n      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"\n      KAFKA_REST_SCHEMA_REGISTRY_URL: \'http://schema-registry:8081\'\n'})}),"\n",(0,r.jsx)(n.h3,{id:"start-the-confluent-platform",children:"Start the Confluent Platform"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"docker-compose up -d\n"})}),"\n",(0,r.jsx)(n.h4,{id:"result",children:"Result:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"# ...\nStatus: Downloaded newer image for confluentinc/cp-kafka-rest:7.8.0\nCreating broker ... done\nCreating schema-registry ... done\nCreating rest-proxy      ... done\nCreating connect         ... done\nCreating ksqldb-server   ... done\nCreating control-center  ... done\nCreating ksql-datagen    ... done\nCreating ksqldb-cli      ... done\n"})}),"\n",(0,r.jsx)(n.h3,{id:"verify-that-the-services-are-up-and-running",children:"Verify that the services are up and running:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"docker-compose ps\n"})}),"\n",(0,r.jsx)(n.h4,{id:"your-output-should-resemble",children:"Your output should resemble:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"     Name                    Command               State                       Ports\n---------------------------------------------------------------------------------------------------------\nbroker            /etc/confluent/docker/run        Up      0.0.0.0:9092->9092/tcp, 0.0.0.0:9101->9101/tcp\nconnect           /etc/confluent/docker/run        Up      0.0.0.0:8083->8083/tcp, 9092/tcp\ncontrol-center    /etc/confluent/docker/run        Up      0.0.0.0:9021->9021/tcp\nksql-datagen      bash -c echo Waiting for K ...   Up\nksqldb-cli        /bin/sh                          Up\nksqldb-server     /etc/confluent/docker/run        Up      0.0.0.0:8088->8088/tcp\nrest-proxy        /etc/confluent/docker/run        Up      0.0.0.0:8082->8082/tcp\nschema-registry   /etc/confluent/docker/run        Up      0.0.0.0:8081->8081/tcp\n"})}),"\n",(0,r.jsx)(n.h2,{id:"ii-uninstall-and-clean-up",children:"II. Uninstall and clean up"}),"\n",(0,r.jsx)(n.h3,{id:"stop-docker",children:"Stop Docker"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"docker-compose stop\n"})}),"\n",(0,r.jsx)(n.h3,{id:"prune-the-docker",children:"Prune the Docker"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'docker system prune -a --volumes --filter "label=io.confluent.docker"\n'})}),"\n",(0,r.jsx)(n.h2,{id:"iii-create-kafka-topics-for-storing-your-data",children:"III. Create Kafka topics for storing your data"}),"\n",(0,r.jsx)(n.p,{children:"In Confluent Platform, real-time streaming events are stored in a Kafka topic."}),"\n",(0,r.jsx)(n.p,{children:"In this step, you create two topics. The topics are named"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"pageviews"}),"\n",(0,r.jsx)(n.li,{children:"users."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"create-the-pageviews-topic",children:"Create the pageviews topic"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Navigate to Control Center at ",(0,r.jsx)(n.a,{href:"http://localhost:9021",children:"http://localhost:9021"})]}),"\n",(0,r.jsxs)(n.li,{children:["Click the ",(0,r.jsx)(n.strong,{children:"controlcenter.cluster"})," tile."]}),"\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.strong,{children:"Topics"})," to open the topics list."]}),"\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.strong,{children:"+ Add topic"})," to start creating the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews"})})," topic; with defaults."]}),"\n"]}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/confluent-platform-create-topi-01.png",width:"400 px",alt:"confluent-platform-create-topi-01.png"}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Result:"})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/pageviews-topic-01.png",width:"400 px",alt:"pageviews-topic-01.png"}),"\n",(0,r.jsx)(n.h3,{id:"create-the-users-topic-with-defaults",children:"Create the users topic with defaults"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/users-topis-01.png",width:"400 px",alt:"users-topis-01.png"}),"\n",(0,r.jsx)(n.h2,{id:"iv-generate-mock-data",children:"IV. Generate mock data"}),"\n",(0,r.jsxs)(n.p,{children:["In Confluent Platform, you get events from an external source by using Kafka Connect. Connectors enable you to stream large volumes of data to and from your Kafka cluster. Confluent publishes many connectors for integrating with external systems, like MongoDB and Elasticsearch. For more information, see the ",(0,r.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/connect/index.html#kafka-connect",children:(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Kafka Connect Overview"})})})," page."]}),"\n",(0,r.jsxs)(n.p,{children:["In this step, you run the ",(0,r.jsx)(n.a,{href:"https://www.confluent.io/hub/confluentinc/kafka-connect-datagen/?_gl=1*1lm6wnr*_gcl_au*MTYyNDM0OTAxNS4xNzMwMTIwNTQ0LjE5NDczMDA3NDguMTczMzg2MTk0NS4xNzMzODYxOTQ1*_ga*NTE5ODY0NDI3LjE3MzAxMjA1NDQ.*_ga_D2D3EGKSGD*MTczNDE2NTU2OC41Mi4xLjE3MzQxNjU1NzguNTAuMC4w&_ga=2.111422604.944557903.1733817958-519864427.1730120544",children:(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Datagen Source Connector"})})})," to generate mock data. The mock data is stored in the pageviews and users topics that you created previously. To learn more about installing connectors, see ",(0,r.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/connect/install.html#connect-install-connectors",children:(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Install Self-Managed Connectors"})})}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["At ",(0,r.jsx)(n.a,{href:"http://localhost:9021",children:"http://localhost:9021"})," click ",(0,r.jsx)(n.strong,{children:"Connect"})]}),"\n",(0,r.jsxs)(n.li,{children:["Click the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"connect-default"})})]}),"\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Add connector"})})]}),"\n",(0,r.jsxs)(n.li,{children:["Select the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"DatagenConnector"})})," tile","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"To see source connectors only, click Filter by category and select Sources."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["In the Name field, enter ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"datagen-pageviews"})})," as the name of the connector."]}),"\n",(0,r.jsxs)(n.li,{children:["Common section:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Key converter class: org.apache.kafka.connect.storage.StringConverter"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["General section:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["kafka.topic: Choose ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews"})})," from the dropdown menu"]}),"\n",(0,r.jsx)(n.li,{children:"max.interval: 100"}),"\n",(0,r.jsxs)(n.li,{children:["quickstart: ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews"})})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Next"})})," to review the connector configuration"]}),"\n"]}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/add-connector-01.png",width:"500 px",alt:"add-connector-01.png"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.strong,{children:"Launch"})]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"run-a-second-instance-of-the-datagen-source-connector-to-produce-mock-data-to-the-users-topic",children:["Run a second instance of the Datagen Source connector to produce mock data to the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"users"})})," topic."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"In the Name field, enter datagen-users as the name of the connector."}),"\n",(0,r.jsxs)(n.li,{children:["Common section:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Key converter class: org.apache.kafka.connect.storage.StringConverter"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["General section:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["kafka.topic: Choose ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"users"})})," from the dropdown menu"]}),"\n",(0,r.jsx)(n.li,{children:"max.interval: 1000"}),"\n",(0,r.jsxs)(n.li,{children:["quickstart: ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"users"})})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Next"})})," to review the connector configuration. When you\u2019re satisfied with the settings, click ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Launch"})}),"."]}),"\n"]}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/add-connector-02.png",width:"500 px",alt:"add-connector-02.png"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["In the navigation menu, click ",(0,r.jsx)(n.strong,{children:"Topics"})," and in the list, click ",(0,r.jsx)(n.strong,{children:"users"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.strong,{children:"Messages"})," to confirm that the datagen-users connector is producing data to the users topic."]}),"\n"]}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/topi-users-produce-message-01.png",width:"800 px",alt:"topi-users-produce-message-01.png"}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.h4,{id:"inspect-the-schema-of-a-topic",children:"Inspect the schema of a topic"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/users-topic-schema-01.png",width:"800 px",alt:"users-topic-schema-01.png"}),"\n",(0,r.jsx)(n.h2,{id:"v-create-a-stream-and-table-by-using-sql-statements",children:"V. Create a stream and table by using SQL statements"}),"\n",(0,r.jsxs)(n.p,{children:["In this step, you create a ",(0,r.jsx)(n.strong,{children:"stream"})," for the pageviews topic and a ",(0,r.jsx)(n.strong,{children:"table"})," for the users topic by using familiar SQL syntax."]}),"\n",(0,r.jsxs)(n.admonition,{type:"note",children:[(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"stream"})," is a an immutable, append-only collection that represents a series of historical facts, or events. After a row is inserted into a stream, the row can never change. You can append new rows at the end of the stream, but you can\u2019t update or delete existing rows."]}),(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"table"})," is a mutable collection that models change over time. It uses row keys to display the most recent data for each key. All but the newest rows for each key are deleted periodically. Also, each row has a timestamp, so you can define a windowed table which enables controlling how to group records that have the same key for stateful operations \u2013 like aggregations and joins \u2013 into time spans. Windows are tracked by record key."]}),(0,r.jsxs)(n.p,{children:["Together, streams and tables comprise a fully realized database. For more information, see ",(0,r.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/ksqldb/concepts/stream-processing.html#ksqldb-concepts-stream-processing",children:(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Stream processing"})})}),"."]})]}),"\n",(0,r.jsx)(n.h3,{id:"create-stream",children:"CREATE STREAM"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"In the Dashboard menu, click ksqlDB."}),"\n",(0,r.jsx)(n.li,{children:"Open the ksqldb1 page."}),"\n",(0,r.jsx)(n.li,{children:"Copy the following SQL into the editor window. This statement registers a stream, named pageviews_stream, on the pageviews topic. Stream and table names are not case-sensitive."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE STREAM pageviews_stream\n  WITH (KAFKA_TOPIC='pageviews', VALUE_FORMAT='AVRO');\n"})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/create-stream-01.png",width:"600 px",alt:"create-stream-01.png"}),"\n",(0,r.jsx)(n.h3,{id:"run-query",children:"Run query"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/run-query-01.png",width:"600 px",alt:"run-query-01.png"}),"\n",(0,r.jsx)(n.h3,{id:"use-a-select-query-to-confirm-that-data-is-moving-through-your-stream",children:"Use a SELECT query to confirm that data is moving through your stream."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"SELECT * FROM pageviews_stream EMIT CHANGES;\n"})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/select-from-pageviews-stream-01.png",width:"600 px",alt:"select-from-pageviews-stream-01.png"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Click Stop to end the SELECT query."}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"stopping-the-select-query-doesnt-stop-data-movement-through-the-stream",children:"Stopping the SELECT query doesn\u2019t stop data movement through the stream."}),"\n",(0,r.jsx)(n.h3,{id:"create-table",children:"CREATE TABLE"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE TABLE users_table (id VARCHAR PRIMARY KEY)\n  WITH (KAFKA_TOPIC='users', VALUE_FORMAT='AVRO');\n"})}),"\n",(0,r.jsx)(n.h4,{id:"output",children:"Output"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/table-created-01.png",width:"600 px",alt:"table-created-01.png"}),"\n",(0,r.jsx)(n.h4,{id:"inspect-the-schemas-of-your-stream-and-table",children:"Inspect the schemas of your stream and table"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/inspect-streams-01.png",width:"800 px",alt:"inspect-streams-01.png"}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/inspect-tables-01.png",width:"800 px",alt:"inspect-tables-01.png"}),"\n",(0,r.jsx)(n.h2,{id:"vi-create-queries-to-process-data",children:"VI. Create queries to process data"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Transient query"}),": a non-persistent, client-side query that you terminate manually or with a LIMIT clause. A transient query doesn\u2019t create a new topic."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Persistent query"}),": a server-side query that outputs a new stream or table that\u2019s backed by a new topic. It runs until you issue the TERMINATE statement. The syntax for a persistent query uses the CREATE STREAM AS SELECT or CREATE TABLE AS SELECT statements."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Push query"}),": A query that produces results continuously to a subscription. The syntax for a push query uses the EMIT CHANGES keyword. Push queries can be transient or persistent."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pull query"}),": A query that gets a result as of \u201cnow\u201d, like a query against a traditional relational database. A pull query runs once and returns the current state of a table. Tables are updated incrementally as new events arrive, so pull queries run with predictably low latency. Pull queries are always transient."]}),"\n"]}),"\n",(0,r.jsxs)(n.h3,{id:"query-for-pageviews",children:["Query for ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews"})})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Copy the following SQL into the editor and click ",(0,r.jsx)(n.strong,{children:"Run query"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"SELECT pageid FROM pageviews_stream EMIT CHANGES LIMIT 3;\n"})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/SELECT-pageid-FROM pageviews_stream-LIMIT.png",width:"800 px",alt:"SELECT-pageid-FROM pageviews_stream-LIMIT.png"}),"\n",(0,r.jsx)(n.h3,{id:"join-your-stream-and-table",children:"Join your stream and table"}),"\n",(0,r.jsxs)(n.p,{children:["In this step, you create a stream named ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"user_pageviews"})})," by using a persistent query that joins ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews_stream"})})," with ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"users_table"})})," on the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"userid"})})," key."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Copy the following SQL into the editor and click ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Run query"})}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE STREAM user_pageviews\n  AS SELECT users_table.id AS userid, pageid, regionid, gender\n    FROM pageviews_stream\n    LEFT JOIN users_table ON pageviews_stream.userid = users_table.id\nEMIT CHANGES;\n"})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/create-stream-user-pageviews-01.png",width:"800 px",alt:"create-stream-user-pageviews-01.png"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.strong,{children:"Streams"})," to open the list of streams that you can access."]}),"\n",(0,r.jsxs)(n.li,{children:["Select ",(0,r.jsx)(n.strong,{children:"USER_PAGEVIEWS"}),", and click ",(0,r.jsx)(n.strong,{children:"Query stream"}),"."]}),"\n"]}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/select-from-user-pageviews-emit-changes-01.png",width:"800 px",alt:"select-from-user-pageviews-emit-changes-01.png"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Click ",(0,r.jsx)(n.strong,{children:"Stop"})," to end the transient push query."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"filter-a-stream",children:"Filter a stream"}),"\n",(0,r.jsxs)(n.p,{children:["In this step, you create a stream, named ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews_region_like_89,"})})," which is made of ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"user_pageviews"})})," rows that have a ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"regionid"})})," value that ends with 8 or 9. Results from this query are written to a new topic, named ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews_filtered_r8_r9"})}),". The topic name is specified explicitly in the query by using the KAFKA_TOPIC keyword."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Copy the following SQL into the editor and click ",(0,r.jsx)(n.strong,{children:"Run"})," query."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE STREAM pageviews_region_like_89\n  WITH (KAFKA_TOPIC='pageviews_filtered_r8_r9', VALUE_FORMAT='AVRO')\n    AS SELECT * FROM user_pageviews\n    WHERE regionid LIKE '%_8' OR regionid LIKE '%_9'\nEMIT CHANGES;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"your-output-should-resemble-1",children:"Your output should resemble:"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/pageviews-filtered-r8-r9-01.png",width:"800 px",alt:"pageviews-filtered-r8-r9-01.png"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Inspect the filtered output of the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews_region_like_89"})})," stream. Copy the following SQL into the editor and click ",(0,r.jsx)(n.strong,{children:"Run query"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"SELECT * FROM pageviews_region_like_89 EMIT CHANGES;\n"})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/select-from=pageviews-region-like-89-emit-changes-01.png",width:"800 px",alt:"select-from=pageviews-region-like-89-emit-changes-01.png"}),"\n",(0,r.jsx)(n.h3,{id:"create-a-windowed-view",children:"Create a windowed view"}),"\n",(0,r.jsxs)(n.p,{children:["In this step, you create a table named ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews_per_region_89"})})," that counts the number of ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews"})})," from regions 8 and 9 in a tumbling window with a SIZE of 30 seconds. The query result is an aggregation that counts and groups rows, so the result is a table, instead of a stream."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Copy the following SQL into the editor and click ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Run query"})}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE TABLE pageviews_per_region_89 WITH (KEY_FORMAT='JSON')\n  AS SELECT userid, gender, regionid, COUNT(*) AS numviews\n    FROM pageviews_region_like_89\n    WINDOW TUMBLING (SIZE 30 SECOND)\n    GROUP BY gender, regionid, userid\n    HAVING COUNT(*) > 1\nEMIT CHANGES;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"your-output-should-resemble-2",children:"Your output should resemble:"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/CREATE-TABLE-pageviews_per_region_89-01.png",width:"800 px",alt:"CREATE-TABLE-pageviews_per_region_89-01.png"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Inspect the windowed output of the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews_per_region_89"})})," table. Copy the following SQL into the editor and click ",(0,r.jsx)(n.strong,{children:"Run query"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"SELECT * FROM pageviews_per_region_89 EMIT CHANGES;\n"})}),"\n",(0,r.jsx)(n.p,{children:"_ Click the table view button (table-view-button)."}),"\n",(0,r.jsx)(n.h4,{id:"your-output-should-resemble-3",children:"Your output should resemble:"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/SELECT-FROM-pageviews_per_region_89-EMIT-CHANGES-01.png",width:"800 px",alt:"SELECT-FROM-pageviews_per_region_89-EMIT-CHANGES-01.png"}),"\n",(0,r.jsx)(n.h4,{id:"the-numviews-column-shows-the-count-of-views-in-a-30-second-window",children:"The NUMVIEWS column shows the count of views in a 30-second window."}),"\n",(0,r.jsx)(n.h3,{id:"snapshot-a-table-by-using-a-pull-query",children:"Snapshot a table by using a pull query"}),"\n",(0,r.jsx)(n.p,{children:"You can get the current state of a table by using a pull query, which returns rows for a specific key at the time you issue the query. A pull query runs once and terminates."}),"\n",(0,r.jsxs)(n.p,{children:["In the step, you query the ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"pageviews_per_region_89"})})," table for all rows that have ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"User_1"})})," in ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Region_9"})}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Copy the following SQL into the editor and click ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"Run query"})}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"SELECT * FROM pageviews_per_region_89\n  WHERE userid = 'User_1' AND gender='FEMALE' AND regionid='Region_9';\n"})}),"\n",(0,r.jsx)(n.p,{children:"Your output should resemble:"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/SELECT-FROM-pageviews_per_region_89- WHERE-01.png",width:"800 px",alt:"SELECT-FROM-pageviews_per_region_89- WHERE-01.png"}),"\n",(0,r.jsx)(n.h3,{id:"inspect-your-streams-and-tables",children:"Inspect your streams and tables"}),"\n",(0,r.jsx)(n.h4,{id:"all-available-streams-and-tables",children:(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"All available streams and tables:"})})}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/available-streams-and-tables-01.png",width:"800 px",alt:"available-streams-and-tables-01.png"}),"\n",(0,r.jsx)(n.h3,{id:"visualize-your-apps-stream-topology",children:"Visualize your app\u2019s stream topology"}),"\n",(0,r.jsx)("img",{src:"/img/streams/ksqlDB/Visualize-your-app-stream-topology-01.png",width:"800 px",alt:"Visualize-your-app-stream-topology-01.png"})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);