"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[1676],{7952:(e,a,s)=>{s.r(a),s.d(a,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>t,metadata:()=>r,toc:()=>h});const r=JSON.parse('{"id":"messaging/kafka/schema-registry","title":"Schema Registry","description":"Definition and Purpose","source":"@site/docs/messaging/kafka/schema-registry.mdx","sourceDirName":"messaging/kafka","slug":"/messaging/kafka/schema-registry","permalink":"/docs/messaging/kafka/schema-registry","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":40,"frontMatter":{"sidebar_position":40},"sidebar":"tutorialSidebar","previous":{"title":"Confluent CLI","permalink":"/docs/messaging/kafka/confluent-cli"},"next":{"title":"Examples","permalink":"/docs/messaging/kafka/examples"}}');var n=s(4848),i=s(8453);const t={sidebar_position:40},o="Schema Registry",c={},h=[{value:"Definition and Purpose",id:"definition-and-purpose",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Schema Types",id:"schema-types",level:2},{value:"Avro",id:"avro",level:3},{value:"Introduction",id:"introduction",level:4},{value:"Schemas",id:"schemas",level:4},{value:"Protobuf",id:"protobuf",level:3},{value:"<em><strong>JSON Schema</strong></em> <br></br>",id:"json-schema-",level:3}];function l(e){const a={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.header,{children:(0,n.jsx)(a.h1,{id:"schema-registry",children:"Schema Registry"})}),"\n",(0,n.jsx)("img",{src:"/img/messaging/kafka/schema-registry-diag-01.png",width:"800 px",alt:"schema-registry-diag-01.png"}),"\n",(0,n.jsx)(a.h2,{id:"definition-and-purpose",children:"Definition and Purpose"}),"\n",(0,n.jsx)(a.p,{children:"Schema Registry provides a centralized repository for managing and validating schemas for topic message data, and for serialization and deserialization of the data over the network. Producers and consumers to Kafka topics can use schemas to ensure data consistency and compatibility as schemas evolve. Schema Registry is a key component for data governance, helping to ensure data quality, adherence to standards, visibility into data lineage, audit capabilities, collaboration across teams, efficient application development protocols, and system performance."}),"\n",(0,n.jsx)(a.p,{children:"The Kafka schema registry serves as an external application that manages data schemas. This registry resides outside the Kafka cluster. It stores, distributes, and approves schemas between producers and consumers. The primary purpose involves ensuring data reliability and consistency. By maintaining a central repository for schemas, the registry facilitates seamless data serialization and deserialization."}),"\n",(0,n.jsx)(a.h2,{id:"key-features",children:"Key Features"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsx)(a.li,{children:"Centralized Schema Storage: Maintains a single source of truth for all schemas."}),"\n",(0,n.jsx)(a.li,{children:"Schema Versioning: Tracks changes by creating new versions for each schema update."}),"\n",(0,n.jsx)(a.li,{children:"Compatibility Checks: Ensures new schemas remain compatible with existing ones."}),"\n",(0,n.jsx)(a.li,{children:"RESTful Interface: Provides a user-friendly API for schema management."}),"\n",(0,n.jsx)(a.li,{children:"Support for Multiple Formats: Handles Avro, JSON Schema, and Protobuf formats."}),"\n"]}),"\n",(0,n.jsx)(a.h2,{id:"schema-types",children:"Schema Types"}),"\n",(0,n.jsx)(a.h3,{id:"avro",children:"Avro"}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:(0,n.jsx)(a.a,{href:"https://avro.apache.org/",children:"https://avro.apache.org/"})})})}),"\n",(0,n.jsx)(a.h4,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsx)(a.p,{children:"Apache Avro\u2122 is a data serialization system."}),"\n",(0,n.jsx)(a.p,{children:"Avro provides:"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsx)(a.li,{children:"Rich data structures."}),"\n",(0,n.jsx)(a.li,{children:"A compact, fast, binary data format."}),"\n",(0,n.jsx)(a.li,{children:"A container file, to store persistent data."}),"\n",(0,n.jsx)(a.li,{children:"Remote procedure call (RPC)."}),"\n",(0,n.jsx)(a.li,{children:"Simple integration with dynamic languages. Code generation is not required to read or write data files nor to use or implement RPC protocols. Code generation as an optional optimization, only worth implementing for statically typed languages."}),"\n"]}),"\n",(0,n.jsx)(a.h4,{id:"schemas",children:"Schemas"}),"\n",(0,n.jsx)(a.p,{children:"Avro relies on schemas. When Avro data is read, the schema used when writing it is always present. This permits each datum to be written with no per-value overheads, making serialization both fast and small. This also facilitates use with dynamic, scripting languages, since data, together with its schema, is fully self-describing."}),"\n",(0,n.jsx)(a.p,{children:"When Avro data is stored in a file, its schema is stored with it, so that files may be processed later by any program. If the program reading the data expects a different schema this can be easily resolved, since both schemas are present."}),"\n",(0,n.jsx)(a.p,{children:"When Avro is used in RPC, the client and server exchange schemas in the connection handshake. (This can be optimized so that, for most calls, no schemas are actually transmitted.) Since both client and server both have the other\u2019s full schema, correspondence between same named fields, missing fields, extra fields, etc. can all be easily resolved."}),"\n",(0,n.jsx)(a.p,{children:"Avro schemas are defined with JSON . This facilitates implementation in languages that already have JSON libraries."}),"\n",(0,n.jsx)(a.h3,{id:"protobuf",children:"Protobuf"}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:(0,n.jsx)(a.a,{href:"https://protobuf.dev/",children:"https://protobuf.dev/"})})})}),"\n",(0,n.jsx)(a.p,{children:"Protocol Buffers are language-neutral, platform-neutral extensible mechanisms for serializing structured data.a"}),"\n",(0,n.jsx)(a.p,{children:"It\u2019s like JSON, except it\u2019s smaller and faster, and it generates native language bindings. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages."}),"\n",(0,n.jsx)(a.p,{children:"Protocol buffers are a combination of the definition language (created in .proto files), the code that the proto compiler generates to interface with data, language-specific runtime libraries, the serialization format for data that is written to a file (or sent across a network connection), and the serialized data."}),"\n",(0,n.jsxs)(a.h3,{id:"json-schema-",children:[(0,n.jsx)(a.a,{href:"https://json-schema.org/",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"JSON Schema"})})})," ",(0,n.jsx)("br",{})]}),"\n",(0,n.jsx)(a.hr,{}),"\n",(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.a,{href:"https://risingwave.com/blog/comprehensive-guide-to-kafka-schema-registry/",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Comprehensive Guide to Kafka Schema Registry"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://docs.confluent.io/platform/current/control-center/topics/schema.html",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Manage Schemas in Confluent Platform"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://docs.confluent.io/platform/current/schema-registry/schema_registry_onprem_tutorial.html#schema-registry-onprem-tutorial",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Review the step-by-step tutorial for using Schema Registry"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://docs.confluent.io/platform/7.8/schema-registry/index.html",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Schema Registry Documentation"})})})," ",(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://docs.confluent.io/platform/current/schema-registry/schema_registry_onprem_tutorial.html#schema-registry-onprem-tutorial",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Tutorial: Use Schema Registry on Confluent Platform to Implement Schemas for a Client Application"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://medium.com/@bulbulmishrajnv/sending-protobuf-message-using-custom-schema-in-kafka-stream-a75017506907",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Sending Protobuf message using custom schema in Kafka stream"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://dzone.com/articles/how-to-use-protobuf-with-apache-kafka-and-schema-r",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"How to Use Protobuf With Apache Kafka and Schema Registry"})})}),(0,n.jsx)("br",{})]}),"\n",(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.a,{href:"https://codingharbour.com/apache-kafka/how-to-create-kafka-consumer-in-java/",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Kafka consumer"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://github.com/codingharbour/kafka-quick-start/blob/master/src/main/java/com/codingharbour/kafka/consumer/SimpleKafkaConsumer.java",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Kafka consumer (github)"})})})," ",(0,n.jsx)("br",{})]}),"\n",(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.a,{href:"https://codingharbour.com/apache-kafka/guide-to-apache-avro-and-kafka/",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Guide to Apache Avro and Kafka"})})})," ",(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://github.com/codingharbour/kafka-avro",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Guide to Apache Avro and Kafka (github)"})})}),(0,n.jsx)("br",{})]}),"\n",(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.a,{href:"https://codingharbour.com/apache-kafka/how-to-use-protobuf-with-apache-kafka-and-schema-registry/",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"kafka-protobuf"})})})," ",(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://github.com/codingharbour/kafka-protobuf",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"kafka-protobuf (github)"})})})," ",(0,n.jsx)("br",{})]}),"\n",(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.a,{href:"https://developer.confluent.io/confluent-tutorials/console-consumer-producer-avro/",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"https://developer.confluent.io/confluent-tutorials/console-consumer-producer-avro/"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://docs.timeplus.com/tutorial-sql-read-avro",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Encode/Decode Avro Messages"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://medium.com/@rramiz.rraza/kafka-programming-in-java-with-avro-serialization-f0121db5a5a1",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Kafka programming in Java with Avro serialization"})})}),(0,n.jsx)("br",{})]}),"\n",(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.a,{href:"https://medium.com/ing-tech-romania/implementing-a-basic-kafka-producer-and-consumer-using-spring-boot-spring-kafka-and-avro-schema-2b6d06e6c4cf",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Implementing a basic Kafka Producer and Consumer using Spring Boot, Spring Kafka and Avro schema"})})}),(0,n.jsx)("br",{}),"\n",(0,n.jsx)(a.a,{href:"https://github.com/dianafagateanu/kafka-demo",children:(0,n.jsx)(a.em,{children:(0,n.jsx)(a.strong,{children:"Implementing a basic Kafka Producer and Consumer using Spring Boot, Spring Kafka and Avro schema (github)"})})}),(0,n.jsx)("br",{})]})]})}function d(e={}){const{wrapper:a}={...(0,i.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},8453:(e,a,s)=>{s.d(a,{R:()=>t,x:()=>o});var r=s(6540);const n={},i=r.createContext(n);function t(e){const a=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:t(e.components),r.createElement(i.Provider,{value:a},e.children)}}}]);