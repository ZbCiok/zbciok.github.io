"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[5420],{5605:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"apache-hadoop/sqoop","title":"SQOOP","description":"Apache Sqoop","source":"@site/docs/apache-hadoop/sqoop.mdx","sourceDirName":"apache-hadoop","slug":"/apache-hadoop/sqoop","permalink":"/docs/apache-hadoop/sqoop","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":200,"frontMatter":{"sidebar_position":200},"sidebar":"tutorialSidebar","previous":{"title":"Setting up a Single Node Cluster","permalink":"/docs/apache-hadoop/install"},"next":{"title":"HBase","permalink":"/docs/apache-hadoop/hbase"}}');var a=n(4848),t=n(8453);const r={sidebar_position:200},i="SQOOP",l={},d=[{value:"What is Apache Sqoop?",id:"what-is-apache-sqoop",level:2},{value:"SQOOP = SQL + HADOOP",id:"sqoop--sql--hadoop",level:4},{value:"Key Features of SQOOP",id:"key-features-of-sqoop",level:2},{value:"Install SQOOP",id:"install-sqoop",level:2},{value:"Verify Installation",id:"verify-installation",level:4}];function p(e){const o={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(o.header,{children:(0,a.jsx)(o.h1,{id:"sqoop",children:"SQOOP"})}),"\n",(0,a.jsxs)(o.p,{children:[(0,a.jsx)(o.a,{href:"https://sqoop.apache.org/",children:(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"Apache Sqoop"})})})," ",(0,a.jsx)("br",{}),"\n",(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:(0,a.jsx)(o.a,{href:"https://sqoop.apache.org/docs/1.99.7/index.html",children:"https://sqoop.apache.org/docs/1.99.7/index.html"})})})," ",(0,a.jsx)("br",{})]}),"\n",(0,a.jsx)(o.h2,{id:"what-is-apache-sqoop",children:"What is Apache Sqoop?"}),"\n",(0,a.jsx)(o.h4,{id:"sqoop--sql--hadoop",children:"SQOOP = SQL + HADOOP"}),"\n",(0,a.jsx)(o.p,{children:(0,a.jsx)(o.em,{children:"(SQL-to-Hadoop)"})}),"\n",(0,a.jsxs)(o.p,{children:["It is a tool designed to support bulk ",(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"export"})})," and ",(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"import"})})," of data into HDFS from structured data stores such as relational databases, enterprise data warehouses, and NoSQL systems. It is a data migration tool based upon a connector architecture which supports plugins to provide connectivity to new external systems."]}),"\n",(0,a.jsx)(o.h2,{id:"key-features-of-sqoop",children:"Key Features of SQOOP"}),"\n",(0,a.jsxs)(o.ul,{children:["\n",(0,a.jsxs)(o.li,{children:[(0,a.jsx)(o.strong,{children:"Parallel Import/Export:"})," Sqoop Big Data Tool uses the YARN framework to import and export data. This provides fault tolerance on top of parallelism"]}),"\n",(0,a.jsxs)(o.li,{children:[(0,a.jsx)(o.strong,{children:"Import Results of SQL Query:"})," Big Data Hadoop Sqoop allows us to import the result returned from an SQL query into HDFS"]}),"\n",(0,a.jsxs)(o.li,{children:[(0,a.jsx)(o.strong,{children:"Connectors for All Major RDBMS Databases:"})," It provides connectors for multiple Relational Database Management System (RDBMS) databases such as MySQL and MS SQL Server"]}),"\n",(0,a.jsxs)(o.li,{children:[(0,a.jsx)(o.strong,{children:"Offers Full and Incremental Load:"})," It can load the whole table or parts of the table by a single command. Hence, it supports the full and incremental load."]}),"\n"]}),"\n",(0,a.jsx)(o.h2,{id:"install-sqoop",children:"Install SQOOP"}),"\n",(0,a.jsxs)(o.p,{children:[(0,a.jsx)(o.a,{href:"https://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html#_introduction",children:(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"Sqoop Tools"})})})," ",(0,a.jsx)("br",{}),"\n",(0,a.jsx)(o.a,{href:"https://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html#_controlling_the_hadoop_installation",children:(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"Controlling the Hadoop Installation"})})})]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{children:"su - hadoop\n"})}),"\n",(0,a.jsxs)(o.p,{children:[(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"/home/hadoop"})}),": ",(0,a.jsx)("br",{}),"\nDownload and untar ",(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz"})})," . ",(0,a.jsx)("br",{})]}),"\n",(0,a.jsx)(o.p,{children:(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:".bashrc:"})})}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{children:'...\n...\nexport HADOOP_HOME=/home/hadoop/hadoop-3.4.1\nexport HADOOP_INSTALL=$HADOOP_HOME\nexport HADOOP_MAPRED_HOME=$HADOOP_HOME\nexport HADOOP_COMMON_HOME=$HADOOP_HOME\nexport HADOOP_HDFS_HOME=$HADOOP_HOME\nexport YARN_HOME=$HADOOP_HOME\nexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native\nexport PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin\nexport HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"\n\nexport SQOOP_HOME=/home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0\nexport PATH=$PATH:$SQOOP_HOME/bin\n'})}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{children:"source ./.bashrc\n"})}),"\n",(0,a.jsx)(o.h4,{id:"verify-installation",children:"Verify Installation"}),"\n",(0,a.jsx)(o.p,{children:(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"sqoop version"})})}),"\n",(0,a.jsx)(o.admonition,{type:"warning",children:(0,a.jsx)(o.p,{children:"hadoop@LL01:~$ sqoop version\nWarning: /home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0/../hbase does not exist! HBase imports will fail.\nPlease set $HBASE_HOME to the root of your HBase installation.\nWarning: /home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0/../hcatalog does not exist! HCatalog jobs will fail.\nPlease set $HCAT_HOME to the root of your HCatalog installation.\nWarning: /home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0/../accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\nWarning: /home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0/../zookeeper does not exist! Accumulo imports will fail.\nPlease set $ZOOKEEPER_HOME to the root of your Zookeeper installation.\n2025-03-16 09:22:05,843 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\nSqoop 1.4.7"})}),"\n",(0,a.jsxs)(o.admonition,{type:"info",children:[(0,a.jsx)(o.p,{children:"So, we'll install:"}),(0,a.jsxs)(o.ul,{children:["\n",(0,a.jsx)(o.li,{children:"HBase"}),"\n",(0,a.jsx)(o.li,{children:"HCatalog"}),"\n",(0,a.jsx)(o.li,{children:"Accumulo"}),"\n",(0,a.jsx)(o.li,{children:"Zookeeper"}),"\n"]})]}),"\n",(0,a.jsx)(o.p,{children:(0,a.jsx)(o.em,{children:(0,a.jsx)(o.strong,{children:"sqoop help"})})}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{children:"...\n...\nAvailable commands:\n  codegen            Generate code to interact with database records\n  create-hive-table  Import a table definition into Hive\n  eval               Evaluate a SQL statement and display the results\n  export             Export an HDFS directory to a database table\n  help               List available commands\n  import             Import a table from a database to HDFS\n  import-all-tables  Import tables from a database to HDFS\n  import-mainframe   Import datasets from a mainframe server to HDFS\n  job                Work with saved jobs\n  list-databases     List available databases on a server\n  list-tables        List available tables in a database\n  merge              Merge results of incremental imports\n  metastore          Run a standalone Sqoop metastore\n  version            Display version information\n"})})]})}function h(e={}){const{wrapper:o}={...(0,t.R)(),...e.components};return o?(0,a.jsx)(o,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453:(e,o,n)=>{n.d(o,{R:()=>r,x:()=>i});var s=n(6540);const a={},t=s.createContext(a);function r(e){const o=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function i(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(t.Provider,{value:o},e.children)}}}]);