"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[9629],{3658:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>p,default:()=>c,frontMatter:()=>i,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"apache-hadoop/Examples/sqoop-import-in-target-dir","title":"Sqoop: Importing Table into Target Directory","description":"Description","source":"@site/docs/apache-hadoop/Examples/sqoop-import-in-target-dir.mdx","sourceDirName":"apache-hadoop/Examples","slug":"/apache-hadoop/Examples/sqoop-import-in-target-dir","permalink":"/docs/apache-hadoop/Examples/sqoop-import-in-target-dir","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":600,"frontMatter":{"sidebar_position":600},"sidebar":"tutorialSidebar","previous":{"title":"MapReduce: Join","permalink":"/docs/apache-hadoop/Examples/mapreduce-join"},"next":{"title":"References","permalink":"/docs/apache-hadoop/references"}}');var o=n(4848),s=n(8453);const i={sidebar_position:600},p="Sqoop: Importing Table into Target Directory",a={},l=[{value:"Description",id:"description",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"MySQL",id:"mysql",level:2},{value:"Import",id:"import",level:2},{value:"Output:",id:"output",level:4},{value:"Output:",id:"output-1",level:4},{value:"Output",id:"output-2",level:4}];function d(e){const t={code:"code",h1:"h1",h2:"h2",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"sqoop-importing-table-into-target-directory",children:"Sqoop: Importing Table into Target Directory"})}),"\n",(0,o.jsx)(t.h2,{id:"description",children:"Description"}),"\n",(0,o.jsx)(t.p,{children:"This Example describes how to import data from MySQL database to Hadoop HDFS."}),"\n",(0,o.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Linux"}),"\n",(0,o.jsx)(t.li,{children:"JDK 11"}),"\n",(0,o.jsx)(t.li,{children:"Hadoop 3.4.1"}),"\n",(0,o.jsx)(t.li,{children:"Sqoop 1.4.7"}),"\n",(0,o.jsx)(t.li,{children:"MySQL"}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"mysql",children:"MySQL"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:["Download MySQL driver into ",(0,o.jsx)(t.code,{children:"/home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0/lib"})]}),"\n",(0,o.jsxs)(t.li,{children:["Create database ",(0,o.jsx)(t.code,{children:"sqoop_test"})]}),"\n",(0,o.jsxs)(t.li,{children:["Create table  ",(0,o.jsx)(t.code,{children:"emp"}),"  in ",(0,o.jsx)(t.code,{children:"sqoop_test"}),", e.g.:"]}),"\n"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"+----------+-------+\n| PersonID | Name  |\n+----------+-------+\n|        1 | Alice |\n|        2 | Bob   |\n+----------+-------+\n"})}),"\n",(0,o.jsx)(t.h2,{id:"import",children:"Import"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"sqoop import \\\n--connect jdbc:mysql://localhost/sqoop_test \\\n--username root -P \\\n--table emp --m 1 \\\n--target-dir /examples/emp1\n"})}),"\n",(0,o.jsx)(t.h4,{id:"output",children:"Output:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"...\n...\n\t\tInput split bytes=87\n\t\tSpilled Records=0\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=0\n\t\tGC time elapsed (ms)=7\n\t\tCPU time spent (ms)=830\n\t\tPhysical memory (bytes) snapshot=281747456\n\t\tVirtual memory (bytes) snapshot=2787991552\n\t\tTotal committed heap usage (bytes)=524288000\n\t\tPeak Map Physical memory (bytes)=281747456\n\t\tPeak Map Virtual memory (bytes)=2787991552\n\tFile Input Format Counters\n\t\tBytes Read=0\n\tFile Output Format Counters\n\t\tBytes Written=14\n"})}),"\n",(0,o.jsx)(t.hr,{}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"hdfs dfs -ls /examples/emp1\n"})}),"\n",(0,o.jsx)(t.h4,{id:"output-1",children:"Output:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"-rw-r--r--   1 hadoop supergroup          0 2025-03-16 12:30 /examples/emp1/_SUCCESS\n-rw-r--r--   1 hadoop supergroup         14 2025-03-16 12:30 /examples/emp1/part-m-00000\n"})}),"\n",(0,o.jsx)(t.hr,{}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"hadoop fs -cat /examples/emp1/part-m-00000\n"})}),"\n",(0,o.jsx)(t.h4,{id:"output-2",children:"Output"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"1,Alice\n2,Bob\n"})})]})}function c(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>p});var r=n(6540);const o={},s=r.createContext(o);function i(e){const t=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function p(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(s.Provider,{value:t},e.children)}}}]);