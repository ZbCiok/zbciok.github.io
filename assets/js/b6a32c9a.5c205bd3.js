"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[5284],{7718:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"apache-hadoop/hbase","title":"HBase","description":"https://hbase.apache.org/","source":"@site/docs/apache-hadoop/hbase.mdx","sourceDirName":"apache-hadoop","slug":"/apache-hadoop/hbase","permalink":"/docs/apache-hadoop/hbase","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":300,"frontMatter":{"sidebar_position":300},"sidebar":"tutorialSidebar","previous":{"title":"SQOOP","permalink":"/docs/apache-hadoop/sqoop"},"next":{"title":"Examples","permalink":"/docs/apache-hadoop/examples"}}');var t=n(4848),r=n(8453);const i={sidebar_position:300},o="HBase",d={},l=[{value:"Applications of Apache HBase:",id:"applications-of-apache-hbase",level:4},{value:"Features of HBase \u2013",id:"features-of-hbase-",level:4},{value:"Advantages Of Apache HBase:",id:"advantages-of-apache-hbase",level:4},{value:"Disadvantages Of Apache HBase:",id:"disadvantages-of-apache-hbase",level:4},{value:"HBase and HDFS",id:"hbase-and-hdfs",level:2},{value:"Install HBase",id:"install-hbase",level:2},{value:"Standalone Mode:",id:"standalone-mode",level:2},{value:"Start Sequence:",id:"start-sequence",level:3},{value:"Create a table",id:"create-a-table",level:2},{value:"put data into your table",id:"put-data-into-your-table",level:3},{value:"Get a single row of data.",id:"get-a-single-row-of-data",level:4},{value:"Ending Sequence:",id:"ending-sequence",level:3},{value:"Pseudo-Distributed Mode:",id:"pseudo-distributed-mode",level:2},{value:"Output",id:"output",level:4}];function c(e){const a={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.header,{children:(0,t.jsx)(a.h1,{id:"hbase",children:"HBase"})}),"\n",(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:(0,t.jsx)(a.a,{href:"https://hbase.apache.org/",children:"https://hbase.apache.org/"})})}),(0,t.jsx)("br",{}),"\n",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:(0,t.jsx)(a.a,{href:"https://hbase.apache.org/book.html",children:"https://hbase.apache.org/book.html"})})})," ",(0,t.jsx)("br",{}),"\n",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:(0,t.jsx)(a.a,{href:"https://hbase.apache.org/book.html#quickstart_pseudo",children:"https://hbase.apache.org/book.html#quickstart_pseudo"})})})," ",(0,t.jsx)("br",{}),"\n",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:(0,t.jsx)(a.a,{href:"https://www.tutorialspoint.com/hbase/hbase_overview.htm",children:"https://www.tutorialspoint.com/hbase/hbase_overview.htm"})})}),(0,t.jsx)("br",{}),"\n",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:(0,t.jsx)(a.a,{href:"https://www.cloudduggu.com/hbase/introduction/",children:"https://www.cloudduggu.com/hbase/introduction/"})})}),(0,t.jsx)("br",{})]}),"\n",(0,t.jsxs)(a.admonition,{type:"note",children:[(0,t.jsx)(a.mdxAdmonitionTitle,{children:(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:(0,t.jsx)(a.a,{href:"https://www.linkedin.com/in/rohit-singh-5a497648/",children:"https://www.linkedin.com/in/rohit-singh-5a497648/"})})})}),(0,t.jsx)(a.p,{children:"Apache HBase is an open-source, NoSQL, distributed big data store. It enables random, strictly consistent, real-time access to petabytes of data. HBase is very effective for handling large, sparse datasets. HBase is a data model that is similar to Google\u2019s big table. It is an open source, distributed database developed by Apache software foundation written in Java. HBase is an essential part of our Hadoop ecosystem. HBase runs on top of HDFS (Hadoop Distributed File System). It can store massive amounts of data from terabytes to petabytes. It is column oriented and horizontally scalable."}),(0,t.jsx)(a.h4,{id:"applications-of-apache-hbase",children:"Applications of Apache HBase:"}),(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"Real-time analytics:"})," HBase is an excellent choice for real-time analytics applications that require low-latency data access. It provides fast read and write performance and can handle large amounts of data, making it suitable for real-time data analysis."]}),(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"Social media applications:"})," HBase is an ideal database for social media applications that require high scalability and performance. It can handle the large volume of data generated by social media platforms and provide real-time analytics capabilities."]}),(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"IoT applications:"})," HBase can be used for Internet of Things (IoT) applications that require storing and processing large volumes of sensor data. HBase\u2019s scalable architecture and fast write performance make it a suitable choice for IoT applications that require low-latency data processing."]}),(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"Online transaction processing:"})," HBase can be used as an online transaction processing (OLTP) database, providing high availability, consistency, and low-latency data access. HBase\u2019s distributed architecture and automatic failover capabilities make it a good fit for OLTP applications that require high availability."]}),(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"Ad serving and clickstream analysis:"})," HBase can be used to store and process large volumes of clickstream data for ad serving and clickstream analysis. HBase\u2019s column-oriented data storage and indexing capabilities make it a good fit for these types of applications."]}),(0,t.jsx)(a.h4,{id:"features-of-hbase-",children:"Features of HBase \u2013"}),(0,t.jsxs)(a.ul,{children:["\n",(0,t.jsx)(a.li,{children:"It is linearly scalable across various nodes as well as modularly scalable, as it divided across various nodes."}),"\n",(0,t.jsx)(a.li,{children:"HBase provides consistent read and writes."}),"\n",(0,t.jsx)(a.li,{children:"It provides atomic read and write means during one read or write process, all other processes are prevented from performing any read or write operations."}),"\n",(0,t.jsx)(a.li,{children:"It provides easy to use Java API for client access."}),"\n",(0,t.jsx)(a.li,{children:"It supports Thrift and REST API for non-Java front ends which supports XML, Protobuf and binary data encoding options."}),"\n",(0,t.jsx)(a.li,{children:"It supports a Block Cache and Bloom Filters for real-time queries and for high volume query optimization."}),"\n",(0,t.jsx)(a.li,{children:"HBase provides automatic failure support between Region Servers."}),"\n",(0,t.jsx)(a.li,{children:"It support for exporting metrics with the Hadoop metrics subsystem to files."}),"\n",(0,t.jsx)(a.li,{children:"It doesn\u2019t enforce relationship within your data."}),"\n",(0,t.jsx)(a.li,{children:"It is a platform for storing and retrieving data with random access."}),"\n"]}),(0,t.jsx)(a.h4,{id:"advantages-of-apache-hbase",children:"Advantages Of Apache HBase:"}),(0,t.jsxs)(a.ul,{children:["\n",(0,t.jsx)(a.li,{children:"Scalability: HBase can handle extremely large datasets that can be distributed across a cluster of machines. It is designed to scale horizontally by adding more nodes to the cluster, which allows it to handle increasingly larger amounts of data."}),"\n",(0,t.jsx)(a.li,{children:"High-performance: HBase is optimized for low-latency, high-throughput access to data. It uses a distributed architecture that allows it to process large amounts of data in parallel, which can result in faster query response times."}),"\n",(0,t.jsx)(a.li,{children:"Flexible data model: HBase\u2019s column-oriented data model allows for flexible schema design and supports sparse datasets. This can make it easier to work with data that has a variable or evolving schema."}),"\n",(0,t.jsx)(a.li,{children:"Fault tolerance: HBase is designed to be fault-tolerant by replicating data across multiple nodes in the cluster. This helps ensure that data is not lost in the event of a hardware or network failure."}),"\n"]}),(0,t.jsx)(a.h4,{id:"disadvantages-of-apache-hbase",children:"Disadvantages Of Apache HBase:"}),(0,t.jsxs)(a.ul,{children:["\n",(0,t.jsx)(a.li,{children:"Complexity: HBase can be complex to set up and manage. It requires knowledge of the Hadoop ecosystem and distributed systems concepts, which can be a steep learning curve for some users."}),"\n",(0,t.jsx)(a.li,{children:"Limited query language: HBase\u2019s query language, HBase Shell, is not as feature-rich as SQL. This can make it difficult to perform complex queries and analyses.\n-No support for transactions: HBase does not support transactions, which can make it difficult to maintain data consistency in some use cases."}),"\n",(0,t.jsx)(a.li,{children:"Not suitable for all use cases: HBase is best suited for use cases where high throughput and low-latency access to large datasets is required. It may not be the best choice for applications that require real-time processing or strong consistency guarantees."}),"\n"]})]}),"\n",(0,t.jsx)(a.h2,{id:"hbase-and-hdfs",children:"HBase and HDFS"}),"\n",(0,t.jsx)(a.p,{children:"In most cases, HBase stores its data in Apache HDFS. This includes the HFiles containing the data, as well as the write-ahead logs (WALs) which store data before it is written to the HFiles and protect against RegionServer crashes. HDFS provides reliability and protection to data in HBase because it is distributed. To operate with the most efficiency, HBase needs data to be available locally. Therefore, it is a good practice to run an HDFS DataNode on each RegionServer."}),"\n",(0,t.jsx)("img",{src:"/img/apache-hadoop/hbase-hdfs-01.png",alt:"hbase-hdfs-01.png"}),"\n",(0,t.jsx)(a.h2,{id:"install-hbase",children:"Install HBase"}),"\n",(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.a,{href:"/docs/apache-hadoop/install",children:(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:"Introductory Information"})})})," ",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"su - hadoop\n"})}),"\n",(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:"/home/hadoop"})}),": ",(0,t.jsx)("br",{}),"\nDownload and untar ",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:"hbase-2.5.11-bin.tar.gz"})})," . ",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"wget http://apache.mirror.gtcomm.net/hbase/stable/hbase-2.5.11-bin.tar.gz\ntar xvf hbase-2.5.11-bin.tar.gz\n"})}),"\n",(0,t.jsxs)(a.p,{children:["Rename ",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:"hbase-2.5.11"})})," --\x3e ",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:"hbase"})})," ",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:".bashrc:"})})}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:'...\n...\nexport HADOOP_HOME=/home/hadoop/hadoop-3.4.1\nexport HADOOP_INSTALL=$HADOOP_HOME\nexport HADOOP_MAPRED_HOME=$HADOOP_HOME\nexport HADOOP_COMMON_HOME=$HADOOP_HOME\nexport HADOOP_HDFS_HOME=$HADOOP_HOME\nexport YARN_HOME=$HADOOP_HOME\nexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native\nexport PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin\nexport HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"\n\nexport SQOOP_HOME=/home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0\nexport PATH=$PATH:$SQOOP_HOME/bin\n\nexport HBASE_HOME=/home/hadoop/hbase\nexport PATH=$PATH:$HBASE_HOME/bin\n'})}),"\n",(0,t.jsx)(a.hr,{}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"nano $HBASE_HOME/conf/hbase-env.sh\n"})}),"\n",(0,t.jsxs)(a.p,{children:["add:",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"export JAVA_HOME=/usr/lib/jvm/java-1.11.0-openjdk-amd64\n#\n# pseudo-distributed mode:\n# export HBASE_REGIONSERVERS=${HBASE_HOME}/conf/regionservers\n# export HBASE_MANAGES_ZK=true\n"})}),"\n",(0,t.jsx)(a.hr,{}),"\n",(0,t.jsx)(a.h2,{id:"standalone-mode",children:"Standalone Mode:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"nano $HBASE_HOME/conf/hbase-site.xml\n"})}),"\n",(0,t.jsxs)(a.p,{children:["change ",(0,t.jsx)(a.code,{children:"<configuration>...</configuration>"})," to:"]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:'<configuration>\n  \x3c!--\n    The following properties are set for running HBase as a single process on a\n    developer workstation. With this configuration, HBase is running in\n    "stand-alone" mode and without a distributed file system. In this mode, and\n    without further configuration, HBase and ZooKeeper data are stored on the\n    local filesystem, in a path under the value configured for `hbase.tmp.dir`.\n    This value is overridden from its default value of `/tmp` because many\n    systems clean `/tmp` on a regular basis. Instead, it points to a path within\n    this HBase installation directory.\n\n    Running against the `LocalFileSystem`, as opposed to a distributed\n    filesystem, runs the risk of data integrity issues and data loss. Normally\n    HBase will refuse to run in such an environment. Setting\n    `hbase.unsafe.stream.capability.enforce` to `false` overrides this behavior,\n    permitting operation. This configuration is for the developer workstation\n    only and __should not be used in production!__\n\n    See also https://hbase.apache.org/book.html#standalone_dist\n\n  <property>\n    <name>hbase.cluster.distributed</name>\n    <value>false</value>\n  </property>\n  <property>\n    <name>hbase.tmp.dir</name>\n    <value>./tmp</value>\n  </property>\n  <property>\n    <name>hbase.unsafe.stream.capability.enforce</name>\n    <value>false</value>\n  </property>\n--\x3e\n  \x3c!-- Standalone Mode --\x3e\n  <property>\n    <name>hbase.rootdir</name>\n    <value>file:///home/hadoop/hbase/hbaseFiles</value>\n  </property>\n  <property>\n    <name>hbase.zookeeper.property.dataDir</name>\n    <value>/home/hadoop/hadoop-3.4.1/zookeeper</value>\n  </property>\n  <property>\n    <name>hbase.unsafe.stream.capability.enforce</name>\n    <value>false</value>\n  </property>\n\n  \x3c!-- Pseudo-Distributed Mode --\x3e\n  \x3c!--\n    <property>\n      <name>hbase.rootdir</name>\n      <value>hdfs://127.0.0.1:9000/hbase</value>\n      <description>\n        hadoop: core-site.xml\n      </description>\n    </property>\n\n    <property>\n      <name>hbase.cluster.distributed</name>\n      <value>true</value>\n    </property>\n\n    <property>\n      <name>hbase.zookeeper.property.clientPort</name>\n      <value>2181</value>\n      <description>\n          default\n      </description>\n    </property>\n\n    <property>\n      <name>hbase.zookeeper.property.dataDir</name>\n      <value>/home/hadoop/hadoop-3.4.1/zookeeper</value>\n    </property>\n\n    <property>\n        <name>zookeeper.registry.async.get.timeout</name>\n        <value>30000</value>\n    </property>\n\n    <property>\n        <name>hbase.wal.provider</name>\n        <value>filesystem</value>\n    </property>\n  --\x3e\n</configuration>\n'})}),"\n",(0,t.jsx)(a.hr,{}),"\n",(0,t.jsx)(a.h3,{id:"start-sequence",children:"Start Sequence:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"$HADOOP_HOME/sbin/start-dfs.sh\n$HADOOP_HOME/sbin/start-yarn.sh\n$HBASE_HOME/bin/start-hbase.sh\n$HBASE_HOME/bin/hbase shell\n"})}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"Jps\n"})}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"5635 NodeManager\n6915 Jps\n5302 ResourceManager\n4790 DataNode\n4604 NameNode\n6077 HMaster\n5006 SecondaryNameNode\n"})}),"\n",(0,t.jsx)(a.h2,{id:"create-a-table",children:"Create a table"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"create 'test', 'cf'\n"})}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"list 'test'\n"})}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"describe 'test'\n"})}),"\n",(0,t.jsx)(a.h3,{id:"put-data-into-your-table",children:"put data into your table"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"put 'test', 'row1', 'cf:a', 'value1'\nput 'test', 'row2', 'cf:b', 'value2'\nput 'test', 'row3', 'cf:b', 'value3'\n"})}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"scan 'test'\n"})}),"\n",(0,t.jsx)(a.h4,{id:"get-a-single-row-of-data",children:"Get a single row of data."}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"get 'test', 'row1'\n"})}),"\n",(0,t.jsx)(a.h3,{id:"ending-sequence",children:"Ending Sequence:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"exit # shell\n$HBASE_HOME/bin/stop-hbase.sh\n$HADOOP_HOME/sbin/stop-yarn.sh\n$HADOOP_HOME/sbin/stop-dfs.sh\n"})}),"\n",(0,t.jsx)(a.h2,{id:"pseudo-distributed-mode",children:"Pseudo-Distributed Mode:"}),"\n",(0,t.jsxs)(a.p,{children:["See: ",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:"hbase-site.xml"})})," and ",(0,t.jsx)(a.em,{children:(0,t.jsx)(a.strong,{children:"hbase-env.sh"})})]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"jps\n"})}),"\n",(0,t.jsx)(a.h4,{id:"output",children:"Output"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"14050 HMaster\n23507 NodeManager\n22821 SecondaryNameNode\n22421 NameNode\n22601 DataNode\n24203 Jps\n13899 HQuorumPeer\n14270 HRegionServer\n23119 ResourceManager\n"})})]})}function h(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>i,x:()=>o});var s=n(6540);const t={},r=s.createContext(t);function i(e){const a=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),s.createElement(r.Provider,{value:a},e.children)}}}]);