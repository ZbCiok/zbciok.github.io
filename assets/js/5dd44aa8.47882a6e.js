"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[2878],{8453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>o});var r=a(6540);const i={},t=r.createContext(i);function s(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(t.Provider,{value:n},e.children)}},8591:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"streams/apache-flink/Examples/stock-price-streams","title":"Stock Price Streams","description":"Description","source":"@site/docs/streams/apache-flink/Examples/stock-price-streams.mdx","sourceDirName":"streams/apache-flink/Examples","slug":"/streams/apache-flink/Examples/stock-price-streams","permalink":"/docs/streams/apache-flink/Examples/stock-price-streams","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":100,"frontMatter":{"sidebar_position":100},"sidebar":"tutorialSidebar","previous":{"title":"Flink Kafka Word Count","permalink":"/docs/streams/apache-flink/Examples/flink-kafka-word-count"},"next":{"title":"References","permalink":"/docs/streams/apache-flink/references"}}');var i=a(4848),t=a(8453);const s={sidebar_position:100},o="Stock Price Streams",c={},l=[{value:"Description",id:"description",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Data Setup",id:"data-setup",level:2},{value:"In our case (above):",id:"in-our-case-above",level:4},{value:"Create topics:",id:"create-topics",level:4},{value:"Download sources",id:"download-sources",level:2},{value:"Setup IntelliJ",id:"setup-intellij",level:2},{value:"Project Structure",id:"project-structure",level:2},{value:"Environment variables",id:"environment-variables",level:3},{value:"KafkaProperties.java",id:"kafkapropertiesjava",level:4},{value:"PropertiesLoader.java",id:"propertiesloaderjava",level:4},{value:".env",id:"env",level:4},{value:"Kafka consumers and producers:",id:"kafka-consumers-and-producers",level:3},{value:"Consumers (a.k.a sources in Flink)",id:"consumers-aka-sources-in-flink",level:4},{value:"Producer (sink in Flink)",id:"producer-sink-in-flink",level:4},{value:"SourceBuilder.java",id:"sourcebuilderjava",level:4},{value:"Deserialization / Serialization",id:"deserialization--serialization",level:3},{value:"StockDeserializer.java",id:"stockdeserializerjava",level:4},{value:"PriceDeserializer.java",id:"pricedeserializerjava",level:4},{value:"StockUpdateSerializer.java",id:"stockupdateserializerjava",level:4},{value:"JacksonConfiguration.java",id:"jacksonconfigurationjava",level:4},{value:"Joining",id:"joining",level:3},{value:"StockPriceJoiner.java",id:"stockpricejoinerjava",level:4},{value:"<em><strong>main</strong></em> class",id:"main-class",level:3},{value:"DataStreamJob.java",id:"datastreamjobjava",level:4},{value:"Run",id:"run",level:2},{value:"Run DataStreamJob",id:"run-datastreamjob",level:4},{value:"Produce stock message:",id:"produce-stock-message",level:4},{value:"Produce price message:",id:"produce-price-message",level:4},{value:"Outputs",id:"outputs",level:2},{value:"IntelliJ log:",id:"intellij-log",level:4},{value:"Kafka:",id:"kafka",level:4}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"stock-price-streams",children:"Stock Price Streams"})}),"\n",(0,i.jsx)(n.h2,{id:"description",children:"Description"}),"\n",(0,i.jsx)(n.p,{children:"What we are interested in here is the processing part of the data, where we take the data, do some manipulations, and extract insights from it."}),"\n",(0,i.jsx)("img",{src:"/img/streams/apache-flink/stock-price-streams-01.png",alt:"stock-price-streams-01.png"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"JDK 17"}),"\n",(0,i.jsx)(n.li,{children:"Maven"}),"\n",(0,i.jsx)(n.li,{children:"IDE (IntelliJ IDEA)"}),"\n",(0,i.jsx)(n.li,{children:"Flink 1.20.0"}),"\n",(0,i.jsx)(n.li,{children:"Docker / Docker Desktop"}),"\n",(0,i.jsx)(n.li,{children:"Docker apache/kafka:3.9.0"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"data-setup",children:"Data Setup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"docker pull apache/kafka:3.9.0\ndocker run -p 9092:9092 apache/kafka:3.9.0\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'docker ps\nCONTAINER ID   IMAGE                COMMAND                  CREATED       STATUS       PORTS                    NAMES\n5076e71c54cd   apache/kafka:3.9.0   "/__cacert_entrypoin\u2026"   5 hours ago   Up 5 hours   0.0.0.0:9092->9092/tcp   fervent_dijkstra\n'})}),"\n",(0,i.jsx)(n.h4,{id:"in-our-case-above",children:"In our case (above):"}),"\n",(0,i.jsxs)(n.p,{children:["Container name: ",(0,i.jsx)(n.strong,{children:"fervent_dijkstra"})]}),"\n",(0,i.jsx)(n.h4,{id:"create-topics",children:"Create topics:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"docker exec -it fervent_dijkstra /bin/bash\ncd /opt/kafka\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"bin/kafka-topics.sh --create --topic price --bootstrap-server localhost:9092\nbin/kafka-topics.sh --create --topic stock --bootstrap-server localhost:9092\nbin/kafka-topics.sh --create --topic stock_update --bootstrap-server localhost:9092\n"})}),"\n",(0,i.jsx)(n.h2,{id:"download-sources",children:"Download sources"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"https://github.com/ZbCiok/zjc-examples/tree/main/streams/flink/live-stock-streaming",children:"https://github.com/ZbCiok/zjc-examples/tree/main/streams/flink/live-stock-streaming"})})})}),"\n",(0,i.jsx)(n.h2,{id:"setup-intellij",children:"Setup IntelliJ"}),"\n",(0,i.jsx)("img",{src:"/img/streams/apache-flink/live-stock-streaming-inllij-config-01.png",alt:"live-stock-streaming-inllij-config-01.png"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(n.h2,{id:"project-structure",children:"Project Structure"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:".\n\u251c\u2500\u2500 docker-kafka.cmds\n\u251c\u2500\u2500 pom.xml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 src\n\u2502\xa0\xa0 \u2514\u2500\u2500 main\n\u2502\xa0\xa0     \u251c\u2500\u2500 java\n\u2502\xa0\xa0     \u2502\xa0\xa0 \u2514\u2500\u2500 com\n\u2502\xa0\xa0     \u2502\xa0\xa0     \u2514\u2500\u2500 abdelrani\n\u2502\xa0\xa0     \u2502\xa0\xa0         \u2514\u2500\u2500 stockstreams\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u251c\u2500\u2500 configuration\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u251c\u2500\u2500 JacksonConfiguration.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u251c\u2500\u2500 KafkaProperties.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u2514\u2500\u2500 PropertiesLoader.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u251c\u2500\u2500 DataStreamJob.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u251c\u2500\u2500 messages\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u251c\u2500\u2500 in\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u2502\xa0\xa0 \u251c\u2500\u2500 Price.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u2502\xa0\xa0 \u2514\u2500\u2500 Stock.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u2514\u2500\u2500 out\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0     \u2514\u2500\u2500 StockUpdate.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u251c\u2500\u2500 operators\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u2514\u2500\u2500 StockPriceJoiner.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u251c\u2500\u2500 serdes\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u251c\u2500\u2500 PriceDeserializer.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u251c\u2500\u2500 StockDeserializer.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2502\xa0\xa0 \u2514\u2500\u2500 StockUpdateSerializer.java\n\u2502\xa0\xa0     \u2502\xa0\xa0             \u2514\u2500\u2500 sources\n\u2502\xa0\xa0     \u2502\xa0\xa0                 \u2514\u2500\u2500 SourceBuilder.java\n\u2502\xa0\xa0     \u2514\u2500\u2500 resources\n\u2502\xa0\xa0         \u2514\u2500\u2500 logback.xml\n\u2514\u2500\u2500 target\n"})}),"\n",(0,i.jsx)(n.h3,{id:"environment-variables",children:"Environment variables"}),"\n",(0,i.jsx)(n.h4,{id:"kafkapropertiesjava",children:"KafkaProperties.java"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"@Data\n@Builder\npublic class KafkaProperties {\n    private String bootstrapServers;\n    private String topic;\n    private String groupId;\n    private String clientId;\n    private String autoOffsetReset;\n}\n"})}),"\n",(0,i.jsx)(n.h4,{id:"propertiesloaderjava",children:"PropertiesLoader.java"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'public class PropertiesLoader {\n    private static final Map<String, String> ENVS = System.getenv();\n\n    public KafkaProperties priceKafkaProperties() {\n        return KafkaProperties.builder()\n                .bootstrapServers(ENVS.get("PRICE_KAFKA_BOOTSTRAP_SERVERS"))\n                .topic(ENVS.get("PRICE_KAFKA_TOPIC"))\n                .groupId(ENVS.get("PRICE_KAFKA_GROUP_ID"))\n                .clientId(ENVS.get("PRICE_KAFKA_CLIENT_ID"))\n                .autoOffsetReset(ENVS.get("PRICE_KAFKA_AUTO_OFFSET_RESET"))\n                .build();\n    }\n\n    public KafkaProperties stockKafkaProperties() {\n        return KafkaProperties.builder()\n                .bootstrapServers(ENVS.get("STOCK_KAFKA_BOOTSTRAP_SERVERS"))\n                .topic(ENVS.get("STOCK_KAFKA_TOPIC"))\n                .groupId(ENVS.get("STOCK_KAFKA_GROUP_ID"))\n                .clientId(ENVS.get("STOCK_KAFKA_CLIENT_ID"))\n                .autoOffsetReset(ENVS.get("STOCK_KAFKA_AUTO_OFFSET_RESET"))\n                .build();\n    }\n\n    public KafkaProperties stockUpdateKafkaProperties() {\n        return KafkaProperties.builder()\n                .bootstrapServers(ENVS.get("STOCK_UPDATE_KAFKA_BOOTSTRAP_SERVERS"))\n                .topic(ENVS.get("STOCK_UPDATE_KAFKA_TOPIC"))\n                .autoOffsetReset(ENVS.get("STOCK_UPDATE_KAFKA_AUTO_OFFSET_RESET"))\n                .build();\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"env",children:".env"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"# Price config\nPRICE_KAFKA_BOOTSTRAP_SERVERS=localhost:9092\nPRICE_KAFKA_TOPIC=price\nPRICE_KAFKA_GROUP_ID=price_group\nRICE_KAFKA_CLIENT_ID=price_client\nPRICE_KAFKA_AUTO_OFFSET_RESET=latest\n\n#Stock config\nSTOCK_KAFKA_BOOTSTRAP_SERVERS=localhost:9092\nSTOCK_KAFKA_TOPIC=stock\nSTOCK_KAFKA_GROUP_ID=stock_group\nSTOCK_KAFKA_CLIENT_ID=stock_client\nSTOCK_KAFKA_AUTO_OFFSET_RESET=latest\n\n# Stock price updates config\nSTOCK_UPDATE_KAFKA_BOOTSTRAP_SERVERS=localhost:9092\nSTOCK_UPDATE_KAFKA_TOPIC=stock_update\nSTOCK_UPDATE_KAFKA_AUTO_OFFSET_RESET=latest\n"})}),"\n",(0,i.jsx)(n.h3,{id:"kafka-consumers-and-producers",children:"Kafka consumers and producers:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.h4,{id:"consumers-aka-sources-in-flink",children:"Consumers (a.k.a sources in Flink)"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.h4,{id:"producer-sink-in-flink",children:"Producer (sink in Flink)"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.h4,{id:"sourcebuilderjava",children:"SourceBuilder.java"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'public class SourceBuilder {\n\n    public static  KafkaSource<Price> priceSource(KafkaProperties kafkaProperties) {\n        return KafkaSource.<Price>builder()\n                .setBootstrapServers(kafkaProperties.getBootstrapServers())\n                .setTopics(kafkaProperties.getTopic())\n                .setValueOnlyDeserializer(new PriceDeserializer())\n                .setGroupId(kafkaProperties.getGroupId())\n                .setStartingOffsets(OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST))\n                .build();\n    }\n\n    public static  KafkaSource<Stock> stockSource(KafkaProperties kafkaProperties) {\n        return KafkaSource.<Stock>builder()\n                .setBootstrapServers(kafkaProperties.getBootstrapServers())\n                .setTopics(kafkaProperties.getTopic())\n                .setDeserializer(new StockDeserializer())\n                .setGroupId(kafkaProperties.getGroupId())\n                .setStartingOffsets(OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST))\n                .setProperty("partition.discovery.interval.ms", "10000") // discover new partitions per 10 seconds\n                .build();\n    }\n\n    public static KafkaSink<StockUpdate> stockUpdateSink(KafkaProperties kafkaProperties) {\n        return KafkaSink.<StockUpdate>builder()\n                .setBootstrapServers(kafkaProperties.getBootstrapServers())\n                .setRecordSerializer(new StockUpdateSerializer(kafkaProperties.getTopic()))\n                .setDeliveryGuarantee(DeliveryGuarantee.AT_LEAST_ONCE) // at least once delivery\n                .build();\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"deserialization--serialization",children:"Deserialization / Serialization"}),"\n",(0,i.jsx)(n.h4,{id:"stockdeserializerjava",children:"StockDeserializer.java"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'@Slf4j\npublic class StockDeserializer implements KafkaRecordDeserializationSchema<Stock> {\n\n    @Override\n    public void deserialize(ConsumerRecord<byte[], byte[]> record, Collector<Stock> out) throws IOException {\n        Stock message = MAPPER.readValue(record.value(), Stock.class);\n        log.info("Received stock with symbol: {}", message.getSymbol());\n        out.collect(message);\n    }\n\n    @Override\n    public TypeInformation<Stock> getProducedType() {\n        return TypeInformation.of(Stock.class);\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"pricedeserializerjava",children:"PriceDeserializer.java"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'@Slf4j\npublic class PriceDeserializer extends AbstractDeserializationSchema<Price>  {\n\n    @Override\n    public Price deserialize(byte[] message) throws IOException {\n        Price priceMessage = MAPPER.readValue(message, Price.class);\n        log.info("Received price message for stock: {}", priceMessage.getSymbol());\n        return priceMessage;\n    }\n\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"stockupdateserializerjava",children:"StockUpdateSerializer.java"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"public class StockUpdateSerializer implements KafkaRecordSerializationSchema<StockUpdate> {\n\n    private final String topic;\n\n    public StockUpdateSerializer(String topic) {\n        this.topic = topic;\n    }\n\n    @SneakyThrows\n    @Nullable\n    @Override\n    public ProducerRecord<byte[], byte[]> serialize(StockUpdate element, KafkaSinkContext context, Long timestamp) {\n        byte[] key = element.getSymbol().getBytes();\n        byte[] result = MAPPER.writeValueAsBytes(element);\n        return new ProducerRecord<>(topic, key, result);\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h4,{id:"jacksonconfigurationjava",children:"JacksonConfiguration.java"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"public class JacksonConfiguration {\n\n    public static final ObjectMapper MAPPER = defaultObjectMapper();\n\n\n    private static ObjectMapper defaultObjectMapper() {\n        return JsonMapper.builder()\n                .addModules(new JavaTimeModule(), new Jdk8Module())\n                .serializationInclusion(NON_NULL)\n                .serializationInclusion(NON_EMPTY)\n                .propertyNamingStrategy(new PropertyNamingStrategies.SnakeCaseStrategy())\n                .enable(SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS)\n                .enable(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY)\n                .enable(DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS)\n                .disable(SerializationFeature.FAIL_ON_EMPTY_BEANS)\n                .disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n                .disable(DeserializationFeature.ADJUST_DATES_TO_CONTEXT_TIME_ZONE)\n                .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS).build();\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"joining",children:"Joining"}),"\n",(0,i.jsx)(n.h4,{id:"stockpricejoinerjava",children:"StockPriceJoiner.java"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.em,{children:(0,i.jsx)(n.strong,{children:"StockPriceJoiner"})})," class extends ",(0,i.jsx)(n.em,{children:(0,i.jsx)(n.strong,{children:"RichCoFlatMapFunction"})}),", which is a function that takes two input streams and produces a single output stream. The ",(0,i.jsx)(n.em,{children:(0,i.jsx)(n.strong,{children:"flatMap1"})})," method is called for each element in the first input stream, and the ",(0,i.jsx)(n.em,{children:(0,i.jsx)(n.strong,{children:"flatMap2"})})," method is called for each element in the second input stream. In this case, we are joining the data from the two input streams and producing a single output stream."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'@Slf4j\npublic class StockPriceJoiner extends RichCoFlatMapFunction<Stock, Price, StockUpdate> {\n\n    /**\n     * The state that is maintained by this process function\n     */\n    private ValueState<Price> priceState;\n\n    @Override\n    public void open(Configuration parameters) throws Exception {\n        priceState = getRuntimeContext().getState(new ValueStateDescriptor<>("price", Price.class));\n    }\n\n    @Override\n    public void flatMap1(Stock stock, Collector<StockUpdate> out) throws Exception {\n        Price price = priceState.value();\n\n        if ((price != null) && (price.getPrice() != null)) {\n            log.info("Joining stock: {} with price: {}", stock.getSymbol(), price.getPrice());\n            out.collect(StockUpdate.builder()\n                    .symbol(stock.getSymbol())\n                    .price(price.getPrice())\n                    .companyName(stock.getCompanyName())\n                    .timestamp(price.getTimestamp())\n                    .build());\n        }\n    }\n\n    @Override\n    public void flatMap2(Price value, Collector<StockUpdate> out) throws Exception {\n        priceState.update(value);\n    }\n}\n'})}),"\n",(0,i.jsxs)(n.h3,{id:"main-class",children:[(0,i.jsx)(n.em,{children:(0,i.jsx)(n.strong,{children:"main"})})," class"]}),"\n",(0,i.jsx)(n.h4,{id:"datastreamjobjava",children:"DataStreamJob.java"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'@Slf4j\npublic class DataStreamJob {\n\n    private static final Set<String> ALLOWED_STOCKS = Set.of("AAPL", "GOOG", "AMZN", "MSFT", "TSLA");\n\n    public static void main(String[] args) throws Exception {\n        // Sets up the execution environment, which is the main entry point to building Flink applications.\n        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n        // Configure the environment\n        configureEnvironment(env);\n\n        // loading properties\n        PropertiesLoader propertiesLoader = new PropertiesLoader();\n\n        // Creating the execution plan\n        DataStreamSource<Stock> stockDataStream = env.fromSource(SourceBuilder.stockSource(propertiesLoader.stockKafkaProperties()),\n                WatermarkStrategy.noWatermarks(),\n                "stock-source");\n\n        DataStreamSource<Price> priceDataStream = env.fromSource(SourceBuilder.priceSource(propertiesLoader.priceKafkaProperties()),\n                WatermarkStrategy.noWatermarks(),\n                "price-source");\n\n        // send the result to a kafka topic using KafkaSink\n        KafkaSink<StockUpdate> stockUpdateKafkaSink = SourceBuilder.stockUpdateSink(propertiesLoader.stockUpdateKafkaProperties());\n\n        stockDataStream\n                .filter(stock -> ALLOWED_STOCKS.contains(stock.getSymbol()))\n                .connect(priceDataStream)\n                .keyBy(Stock::getSymbol, Price::getSymbol)\n                .flatMap(new StockPriceJoiner())\n                .name("join-stock-price")\n                .map(stockUpdate -> {\n                    log.info("stock price update: {}", stockUpdate);\n                    return stockUpdate;\n                })\n                .sinkTo(stockUpdateKafkaSink);\n\n\n        // Execute program, beginning computation.\n        env.execute("StockPriceStreamJob");\n\n    }\n\n    private static void configureEnvironment(StreamExecutionEnvironment env) {\n        // automatically recover from failures\n        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(\n                3, // number of restart attempts\n                Time.seconds(10) // delay\n        ));\n        // disable kryo serialization and use the PojoSerializer (for better efficiency)\n        env.getConfig().disableGenericTypes();\n        // configuring the task manager\n        env.configure(getConfiguration());\n    }\n\n    // Configure the task manager\n    private static Configuration getConfiguration() {\n        Configuration config = new Configuration();\n        config.setString("taskmanager.cpu.cores", "4");\n        config.setString("taskmanager.memory.task.heap.size", "1024m");\n        return config;\n    }\n}\n\n'})}),"\n",(0,i.jsx)(n.h2,{id:"run",children:"Run"}),"\n",(0,i.jsx)(n.h4,{id:"run-datastreamjob",children:"Run DataStreamJob"}),"\n",(0,i.jsx)(n.p,{children:"DataStreamJob.java"}),"\n",(0,i.jsx)(n.h4,{id:"produce-stock-message",children:"Produce stock message:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'bin/kafka-console-producer.sh --topic stock --bootstrap-server localhost:9092\n>{ "symbol": "GOOG", "company_name": "Alphabet Inc (Google)" }\n'})}),"\n",(0,i.jsx)(n.h4,{id:"produce-price-message",children:"Produce price message:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'bin/kafka-console-producer.sh --topic price --bootstrap-server localhost:9092\n>{ "symbol": "GOOG", "timestamp": "1712443970", "price": 1.5 }\n'})}),"\n",(0,i.jsx)(n.h2,{id:"outputs",children:"Outputs"}),"\n",(0,i.jsx)(n.h4,{id:"intellij-log",children:"IntelliJ log:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\n[Source: stock-source -> Filter (11/28)#0] INFO  c.a.s.serdes.StockDeserializer - Received stock with symbol: GOOG\n[Source: price-source (4/28)#0] INFO  c.a.s.serdes.PriceDeserializer - Received price message for stock: GOOG\n[Source: stock-source -> Filter (11/28)#0] INFO  c.a.s.serdes.StockDeserializer - Received stock with symbol: GOOG\n[join-stock-price -> Map -> Sink: Writer -> Sink: Committer (18/28)#0] INFO  c.a.s.operators.StockPriceJoiner - Joining stock: GOOG with price: 1.5\n[join-stock-price -> Map -> Sink: Writer -> Sink: Committer (18/28)#0] INFO  c.a.stockstreams.DataStreamJob - stock price update: StockUpdate(symbol=GOOG, companyName=Alphabet Inc (Google), timestamp=1712443970, price=1.5)\n"})}),"\n",(0,i.jsx)(n.h4,{id:"kafka",children:"Kafka:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'\nbin/kafka-console-consumer.sh --topic stock_update --from-beginning --bootstrap-server localhost:9092092\n{"symbol":"GOOG","timestamp":"1712443970","price":1.5}\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Example based on:"}),(0,i.jsx)("br",{}),"\n",(0,i.jsx)(n.em,{children:(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"https://abdelrani.com/blog/streaming-data-using-apache-flink",children:"https://abdelrani.com/blog/streaming-data-using-apache-flink"})})})]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);