"use strict";(self.webpackChunkjreact_com_docsaurus_01=self.webpackChunkjreact_com_docsaurus_01||[]).push([[8688],{2533:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>s});const r=JSON.parse('{"id":"apache-hadoop/Examples/mapreduce-matrix-vector-multiplication","title":"MapReduce: Matrix-Vector Multiplication","description":"Based on...","source":"@site/docs/apache-hadoop/Examples/mapreduce-matrix-vector-multiplication.mdx","sourceDirName":"apache-hadoop/Examples","slug":"/apache-hadoop/Examples/mapreduce-matrix-vector-multiplication","permalink":"/docs/apache-hadoop/Examples/mapreduce-matrix-vector-multiplication","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":400,"frontMatter":{"sidebar_position":400},"sidebar":"tutorialSidebar","previous":{"title":"MapReduce: Inverted Index","permalink":"/docs/apache-hadoop/Examples/mapreduce-inverted-index"},"next":{"title":"MapReduce: Join","permalink":"/docs/apache-hadoop/Examples/mapreduce-join"}}');var o=t(4848),i=t(8453);const a={sidebar_position:400},l="MapReduce: Matrix-Vector Multiplication",c={},s=[{value:"Description",id:"description",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"HDFS",id:"hdfs",level:2},{value:"Create files in HDFS",id:"create-files-in-hdfs",level:3},{value:"Create local files:",id:"create-local-files",level:4},{value:"Copy the above files to HDFS:",id:"copy-the-above-files-to-hdfs",level:4},{value:"Check if both files have been copied:",id:"check-if-both-files-have-been-copied",level:4},{value:"Output:",id:"output",level:4},{value:"Java Program",id:"java-program",level:2},{value:"Program Structure",id:"program-structure",level:4},{value:"pom.xml",id:"pomxml",level:4},{value:"Driver.java",id:"driverjava",level:4},{value:"CellMultiplication.java",id:"cellmultiplicationjava",level:4},{value:"CellSum.java",id:"cellsumjava",level:4},{value:"Run",id:"run",level:2},{value:"Verify",id:"verify",level:3},{value:"Sub:",id:"sub",level:3},{value:"Output:",id:"output-1",level:4},{value:"Sum:",id:"sum",level:3},{value:"Output:",id:"output-2",level:4},{value:"Content:",id:"content",level:3},{value:"Sub:",id:"sub-1",level:3},{value:"Output:",id:"output-3",level:4},{value:"Sum:",id:"sum-1",level:3},{value:"Output:",id:"output-4",level:4}];function p(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"mapreduce-matrix-vector-multiplication",children:"MapReduce: Matrix-Vector Multiplication"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/caizkun/mapreduce-examples/tree/master/MatrixVectorMultiplication",children:(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:"Based on..."})})})}),"\n",(0,o.jsx)(n.h2,{id:"description",children:"Description"}),"\n",(0,o.jsx)(n.p,{children:"Calculate the product of a matrix M (assumed sparse) and a vector v:"}),"\n",(0,o.jsx)("img",{src:"/img/apache-hadoop/example-04-img-01.png",alt:"example-04-img-01.png"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Workflow"})," - 2 MapReduce jobs"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["CellMultiplication: Mapper1 + Mapper2 ---\x3e Reducer\nMapper1: read the non-zero elements in the matrix file ",(0,o.jsx)(n.code,{children:"(row, col, M[row][col])"}),"\ninput: ",(0,o.jsx)(n.code,{children:"<offset, line>"}),"\noutput: ",(0,o.jsx)(n.code,{children:"<col, row=M[row][col]>"}),"\nMapper2: read the vector\ninput: ",(0,o.jsx)(n.code,{children:"<offset, line>"}),"\noutput: ",(0,o.jsx)(n.code,{children:"<row, v[row]>"}),"\nReducer: multiply a matrix column with the corresponding vector row\ninput: ",(0,o.jsx)(n.code,{children:"<col, (row1=M[row1][col], row2=M[row2][col], ..., v[col])>"}),"\noutput: ",(0,o.jsx)(n.code,{children:"<row, M[row][col]*v[col]>"})]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"CellSum: Mapper ---\x3e Reducer"}),"\n",(0,o.jsxs)(n.p,{children:["Mapper: read the intermediate result of cell multiplication\ninput: ",(0,o.jsx)(n.code,{children:"<offset, line>"}),"\noutput: ",(0,o.jsx)(n.code,{children:"<row, M[row][col]*v[col]>"})]}),"\n",(0,o.jsxs)(n.p,{children:["Reducer: sum up all the cell product to the final value for each vector row\ninput: ",(0,o.jsx)(n.code,{children:"<row, (M[row][col1]*v[col1], M[row][col2]*v[col2], ...)>"}),"\noutput: ",(0,o.jsx)(n.code,{children:"<row, M[row][col1]*v[col1] + M[row][col2]*v[col2] + ...>"})]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Linux"}),"\n",(0,o.jsx)(n.li,{children:"JDK 11"}),"\n",(0,o.jsx)(n.li,{children:"Maven"}),"\n",(0,o.jsx)(n.li,{children:"Hadoop 3.4.1"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"hdfs",children:"HDFS"}),"\n",(0,o.jsx)(n.h3,{id:"create-files-in-hdfs",children:"Create files in HDFS"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"su - hadoop\nstart-dfs.sh\nstart-yarn.sh\n"})}),"\n",(0,o.jsx)(n.h4,{id:"create-local-files",children:"Create local files:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"/home/hadoop/examples/MatrixVectorMultiplication/input/matrix/matrix.txt\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"/home/hadoop/examples/MatrixVectorMultiplication/input/vector/vector.txt\n"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:"matrix.txt"})})," and ",(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:"vector.txt"})})," see ",(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:"Java Program"})})]}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(n.h4,{id:"copy-the-above-files-to-hdfs",children:"Copy the above files to HDFS:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nhdfs dfs -copyFromLocal /home/hadoop/examples/MatrixVectorMultiplication/input/matrix /examples/MatrixVectorMultiplication/input/matrix\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nhdfs dfs -copyFromLocal /home/hadoop/examples/MatrixVectorMultiplication/input/vector /examples/MatrixVectorMultiplication/input/vector\n"})}),"\n",(0,o.jsx)(n.h4,{id:"check-if-both-files-have-been-copied",children:"Check if both files have been copied:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"hdfs dfs -ls /examples/MatrixVectorMultiplication/input\n"})}),"\n",(0,o.jsx)(n.h4,{id:"output",children:"Output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"./hdfs dfs -ls /examples/MatrixVectorMultiplication/input\nFound 2 items\ndrwxr-xr-x   - hadoop supergroup          0 2025-03-14 09:21 /examples/MatrixVectorMultiplication/input/matrix\ndrwxr-xr-x   - hadoop supergroup          0 2025-03-14 09:22 /examples/MatrixVectorMultiplication/input/vector\n"})}),"\n",(0,o.jsx)(n.h2,{id:"java-program",children:"Java Program"}),"\n",(0,o.jsx)(n.h4,{id:"program-structure",children:"Program Structure"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:".\n\u251c\u2500\u2500 dependency-reduced-pom.xml\n\u251c\u2500\u2500 input\n\u2502\xa0\xa0 \u251c\u2500\u2500 matrix\n\u2502\xa0\xa0 \u2502\xa0\xa0 \u2514\u2500\u2500 matrix.txt\n\u2502\xa0\xa0 \u2514\u2500\u2500 vector\n\u2502\xa0\xa0     \u2514\u2500\u2500 vector.txt\n\u251c\u2500\u2500 pom.xml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 src\n\u2502\xa0\xa0 \u2514\u2500\u2500 main\n\u2502\xa0\xa0     \u2514\u2500\u2500 java\n\u2502\xa0\xa0         \u251c\u2500\u2500 CellMultiplication.java\n\u2502\xa0\xa0         \u251c\u2500\u2500 CellSum.java\n\u2502\xa0\xa0         \u2514\u2500\u2500 Driver.java\n\u2514\u2500\u2500 toy_example.png\n"})}),"\n",(0,o.jsx)(n.h4,{id:"pomxml",children:"pom.xml"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'<?xml version="1.0" encoding="UTF-8"?>\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.example</groupId>\n    <artifactId>MatrixVectorMultiplication</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <properties>\n        <target.java.version>11</target.java.version>\n        <maven.compiler.source>${target.java.version}</maven.compiler.source>\n        <maven.compiler.target>${target.java.version}</maven.compiler.target>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    </properties>\n\n    <dependencies>\n        \x3c!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-core --\x3e\n        <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-mapreduce-client-core</artifactId>\n            <version>3.4.1</version>\n        </dependency>\n\n        \x3c!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-core --\x3e\n        <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-core</artifactId>\n            <version>1.2.1</version>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n\n            \x3c!-- Java Compiler --\x3e\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>3.1</version>\n                <configuration>\n                    <source>${target.java.version}</source>\n                    <target>${target.java.version}</target>\n                </configuration>\n            </plugin>\n\n            \x3c!-- We use the maven-shade plugin to create a fat jar that contains all necessary dependencies. --\x3e\n            \x3c!-- Change the value of <mainClass>...</mainClass> if your program entry point changes. --\x3e\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-shade-plugin</artifactId>\n                <version>3.0.0</version>\n                <executions>\n                    \x3c!-- Run shade goal on package phase --\x3e\n                    <execution>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>shade</goal>\n                        </goals>\n                        <configuration>\n                            <artifactSet>\n                                <excludes>\n                                    <exclude>org.apache.flink:flink-shaded-force-shading</exclude>\n                                    <exclude>com.google.code.findbugs:jsr305</exclude>\n                                    <exclude>org.slf4j:*</exclude>\n                                    <exclude>org.apache.logging.log4j:*</exclude>\n                                </excludes>\n                            </artifactSet>\n                            <filters>\n                                <filter>\n                                    \x3c!-- Do not copy the signatures in the META-INF folder.\n                                    Otherwise, this might cause SecurityExceptions when using the JAR. --\x3e\n                                    <artifact>*:*</artifact>\n                                    <excludes>\n                                        <exclude>META-INF/*.SF</exclude>\n                                        <exclude>META-INF/*.DSA</exclude>\n                                        <exclude>META-INF/*.RSA</exclude>\n                                    </excludes>\n                                </filter>\n                            </filters>\n                            <transformers>\n                                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">\n                                    <mainClass>Driver</mainClass>\n                                </transformer>\n                            </transformers>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n\n    </build>\n</project>\n'})}),"\n",(0,o.jsx)(n.h4,{id:"driverjava",children:"Driver.java"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-java",children:"public class Driver {\n\n    public static void main(String[] args) throws Exception {\n        CellMultiplication multiplication = new CellMultiplication();\n        CellSum sum = new CellSum();\n\n        // parse args\n        String matrixInputPath = args[0];\n        String vectorInputPath = args[1];\n        String subSumOutputPath = args[2];\n        String sumOutputPath = args[3];\n\n        // run the first job\n        String[] cellMultiplicationArgs = {matrixInputPath, vectorInputPath, subSumOutputPath};\n        multiplication.main(cellMultiplicationArgs);\n\n        // run the second job\n        String[] cellSumArgs = {subSumOutputPath, sumOutputPath};\n        sum.main(cellSumArgs);\n    }\n}\n"})}),"\n",(0,o.jsx)(n.h4,{id:"cellmultiplicationjava",children:"CellMultiplication.java"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-java",children:'import org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.conf.Configured;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.MultipleInputs;\nimport org.apache.hadoop.mapreduce.lib.input.TextInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.Tool;\nimport org.apache.hadoop.util.ToolRunner;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class CellMultiplication extends Configured implements Tool {\n\n    public static class MatrixReaderMapper extends Mapper<LongWritable, Text, Text, Text> {\n        @Override\n        public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n            // input: <offset, line>, each line is: row col element\n            // output: <col, row=element>\n\n            String[] cell = value.toString().trim().split("\\t");\n            String col = cell[1];\n            String rowVal = cell[0] + "=" + cell[2];\n            context.write(new Text(col), new Text(rowVal));\n        }\n    }\n\n    public static class VectorReaderMapper extends Mapper<LongWritable, Text, Text, Text> {\n        @Override\n        public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n            // input: <offset, line>, each line is: row element\n            // output: <row, element>\n\n            String[] cell = value.toString().trim().split("\\t");\n            context.write(new Text(cell[0]), new Text(cell[1]));\n        }\n    }\n\n    public static class CellReducer extends Reducer<Text, Text, Text, Text> {\n        @Override\n        public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {\n            // input: <col, row1=element1, row2=element2, ..., v>\n            // output: <row, element * v>\n\n            double vecCell = 0.0;\n            List<String> matrixRow = new ArrayList<String>();\n            for (Text value : values) {\n                String val = value.toString();\n                if (val.contains("=")) {\n                    matrixRow.add(val);\n                } else {\n                    vecCell = Double.parseDouble(val);\n                }\n            }\n\n            for (String rowVal : matrixRow) {\n                String row = rowVal.split("=")[0];\n                double value = Double.parseDouble(rowVal.split("=")[1]) * vecCell;\n                context.write(new Text(row), new Text(String.valueOf(value)));\n            }\n        }\n    }\n\n    public int run(String[] args) throws Exception {\n        if (args.length != 3) {\n            System.err.printf("Usage: %s [generic options] <input> <output>\\n", getClass().getSimpleName());\n            ToolRunner.printGenericCommandUsage(System.err);\n            return -1;\n        }\n\n        Configuration conf = new Configuration();\n\n        Job job = Job.getInstance(conf, "Cell Multiplication");\n        job.setJarByClass(CellMultiplication.class);\n        job.setReducerClass(CellReducer.class);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(Text.class);\n\n        // Multiple input paths: one for each Mapper\n        // No need to use job.setMapperClass()\n        MultipleInputs.addInputPath(job, new Path(args[0]), TextInputFormat.class, MatrixReaderMapper.class);\n        MultipleInputs.addInputPath(job, new Path(args[1]), TextInputFormat.class, VectorReaderMapper.class);\n\n        FileOutputFormat.setOutputPath(job, new Path(args[2]));\n\n        return job.waitForCompletion(true)? 0 : 1;\n    }\n\n    public static void main(String[] args) throws Exception {\n        int exitCode = ToolRunner.run(new CellMultiplication(), args);\n        if (exitCode == 1) {\n            System.exit(exitCode);\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(n.h4,{id:"cellsumjava",children:"CellSum.java"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-java",children:'import org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.conf.Configured;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.DoubleWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.Tool;\nimport org.apache.hadoop.util.ToolRunner;\n\nimport java.io.IOException;\nimport java.text.DecimalFormat;\n\npublic class CellSum extends Configured implements Tool {\n\n    public static class SumMapper extends Mapper<LongWritable, Text, Text, DoubleWritable> {\n        @Override\n        public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n            // input: <offset, line>, each line is: row subSum\n            // output: <row, subSum>\n\n            String[] cell = value.toString().trim().split("\\t");\n            double subSum = Double.parseDouble(cell[1]);\n            context.write(new Text(cell[0]), new DoubleWritable(subSum));\n        }\n    }\n\n    public static class SumReducer extends Reducer<Text, DoubleWritable, Text, DoubleWritable> {\n        @Override\n        public void reduce(Text key, Iterable<DoubleWritable> values, Context context) throws IOException, InterruptedException {\n            // input: <row, (subSum1, subSum2, ...)>\n            // output: <row, subSum1+subSum2+...>\n\n            double sum = 0.0;\n            for (DoubleWritable subSum : values) {\n                sum += subSum.get();\n            }\n            DecimalFormat df = new DecimalFormat("#.0000");\n            sum = Double.valueOf(df.format(sum));\n            context.write(key, new DoubleWritable(sum));\n        }\n    }\n\n    public int run(String[] args) throws Exception {\n        if (args.length != 2) {\n            System.err.printf("Usage: %s [generic options] <input> <output>\\n", getClass().getSimpleName());\n            ToolRunner.printGenericCommandUsage(System.err);\n            return -1;\n        }\n\n        Configuration conf = new Configuration();\n\n        Job job = Job.getInstance(conf, "Cell Sum");\n        job.setJarByClass(CellSum.class);\n        job.setMapperClass(SumMapper.class);\n        job.setReducerClass(SumReducer.class);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(DoubleWritable.class);\n\n        FileInputFormat.addInputPath(job, new Path(args[0]));\n        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n\n        return job.waitForCompletion(true)? 0 : 1;\n    }\n\n    public static void main(String[] args) throws Exception {\n        int exitCode = ToolRunner.run(new CellSum(), args);\n        if (exitCode == 1) {\n            System.exit(exitCode);\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(n.h2,{id:"run",children:"Run"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"mvn clean package\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nhadoop jar /home/hadoop/examples/MatrixVectorMultiplication/MatrixVectorMultiplication-1.0-SNAPSHOT.jar /examples/MatrixVectorMultiplication/input/matrix/matrix/ /examples/MatrixVectorMultiplication/input/vector/vector/ /examples/MatrixVectorMultiplication/output/sub /examples/MatrixVectorMultiplication/output/sum\n"})}),"\n",(0,o.jsx)(n.h3,{id:"verify",children:"Verify"}),"\n",(0,o.jsx)(n.h3,{id:"sub",children:"Sub:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"hdfs dfs -ls /examples/MatrixVectorMultiplication/output/sub\n"})}),"\n",(0,o.jsx)(n.h4,{id:"output-1",children:"Output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\n-rw-r--r--   1 hadoop supergroup          0 2025-03-14 12:02 /examples/MatrixVectorMultiplication/output/sub/_SUCCESS\n-rw-r--r--   1 hadoop supergroup         37 2025-03-14 12:02 /examples/MatrixVectorMultiplication/output/sub/part-r-00000\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"sum",children:"Sum:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"hdfs dfs -ls /examples/MatrixVectorMultiplication/output/sum\n"})}),"\n",(0,o.jsx)(n.h4,{id:"output-2",children:"Output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\n-rw-r--r--   1 hadoop supergroup          0 2025-03-14 12:02 /examples/MatrixVectorMultiplication/output/sum/_SUCCESS\n-rw-r--r--   1 hadoop supergroup         25 2025-03-14 12:02 /examples/MatrixVectorMultiplication/output/sum/part-r-00000\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"content",children:"Content:"}),"\n",(0,o.jsx)(n.h3,{id:"sub-1",children:"Sub:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"hdfs dfs -cat /examples/MatrixVectorMultiplication/output/sub/part-r-00000\n"})}),"\n",(0,o.jsx)(n.h4,{id:"output-3",children:"Output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"4\t8.0\n2\t4.0\n1\t0.0\n3\t-3.0\n1\t2.0\n2\t2.0\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"sum-1",children:"Sum:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"hdfs dfs -cat /examples/MatrixVectorMultiplication/output/sum/part-r-00000\n"})}),"\n",(0,o.jsx)(n.h4,{id:"output-4",children:"Output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"1\t2.0\n2\t6.0\n3\t-3.0\n4\t8.0\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.p,{children:["Source of the java program:",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"https://github.com/ZbCiok/zjc-examples/tree/main/streams/hadoop/MatrixVectorMultiplication",children:"https://github.com/ZbCiok/zjc-examples/tree/main/streams/hadoop/MatrixVectorMultiplication"})})})]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>l});var r=t(6540);const o={},i=r.createContext(o);function a(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);